#!/hadron/knippsch/Enthought/Canopy_64bit/User/bin/python
##!/usr/bin/python
################################################################################
#
# Author: Christian Jost (jost@hiskp.uni-bonn.de)
# Date:   Februar 2015
#
# Copyright (C) 2015 Christian Jost
# 
# This program is free software: you can redistribute it and/or modify it under 
# the terms of the GNU General Public License as published by the Free Software 
# Foundation, either version 3 of the License, or (at your option) any later 
# version.
# 
# This program is distributed in the hope that it will be useful, but WITHOUT 
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS 
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with tmLQCD. If not, see <http://www.gnu.org/licenses/>.
#
################################################################################
#
# Function: This is the start of the eta/eta' analysis program
#
# For informations on input parameters see the description of the function.
#
################################################################################

import os
import numpy as np
import numpy.ma as ma
import sys

import analysis as ana

def print_results(data, staterror, systerror):
    """Prints the results to screen
    """
    print("E dE - +  delta ddelta - +  tan dtan - +  sin2 dsin2 - +")
    for _i in range(data.shape[0]):
        print("%.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf  %.7lf %.7lf  %.7lf %.7lf" % (
              data[_i,0], staterror[_i,0], systerror[0,_i,0], systerror[1,_i,0],
              data[_i,1], staterror[_i,1], systerror[0,_i,1], systerror[1,_i,1],
              data[_i,2], staterror[_i,2], systerror[0,_i,2], systerror[1,_i,2],
              data[_i,3], staterror[_i,3], systerror[0,_i,3], systerror[1,_i,3]))

def write_results(data, staterror, systerror, filename):
    """Writes the results to file.
    """
    # check whether file exists
    if os.path.isfile(filename):
        print(filename + " already exists, overwritting...")
    # open file for writting
    outfile = open(filename, "w")
    outfile.write("E dE - +  delta ddelta - +  tan dtan - +  sin2 dsin2 - +\n")
    for _i in range(data.shape[0]):
        outfile.write("%.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf  %.7lf %.7lf  %.7lf %.7lf\n" % (
              data[_i,0], staterror[_i,0], systerror[0,_i,0], systerror[1,_i,0],
              data[_i,1], staterror[_i,1], systerror[0,_i,1], systerror[1,_i,1],
              data[_i,2], staterror[_i,2], systerror[0,_i,2], systerror[1,_i,2],
              data[_i,3], staterror[_i,3], systerror[0,_i,3], systerror[1,_i,3]))

def read_new_data(nbsamples, path, filelist, tmin, lattice, d2, verbose=False):
    """Read in data for a new configuration.
    """
    # read in data for GEVP
    if verbose:
        print("reading data")
    corr_mat = ana.create_corr_matrix(nbsamples, path, filelist)
    ana.write_data(corr_mat, "./raw_data/corr_mat_rho_%s_TP%d.npy"%(lattice,d2))
    # solve the GEVP
    if verbose:
        print("solving GEVP")
    gevp_mat = ana.calculate_gevp(corr_mat, tmin)
    ana.write_data(gevp_mat, "./raw_data/gevp_mat_rho_%s_TP%d.npy"%(lattice,d2))
    # write in ASCII
    ana.write_data_ascii(gevp_mat,"./raw_data/gevp_rho_%s_TP%d.dat"%(lattice,d2))
    return gevp_mat

def read_pi(ens, pilist, datafolder, nsamples, lattice, d, readnew=True, 
            verbose=True):
    path = ["/hiskp2/correlators/A30.32_L32_T64_beta190_mul0030_musig150_mudel190_kappa1632720/ev220/liuming/",
            "/hiskp2/correlators/A40.20_L20_T48_beta190_mul0040_musig150_mudel190_kappa1632700/ev066/liuming/",
            "/hiskp2/correlators/A40.24_L24_T48_beta190_mul0040_musig150_mudel190_kappa1632700/ev120/liuming/",
            "/hiskp2/correlators/A40.32_L32_T64_beta190_mul0040_musig150_mudel190_kappa1632700/liuming/",
            "/hiskp2/correlators/A60.24_L24_T48_beta190_mul0060_musig150_mudel190_kappa1632650/ev120/liuming/",
            "/hiskp2/correlators/A80.24_L24_T48_beta190_mul0080_musig150_mudel190_kappa1632600/ev120/liuming/",
            "/hiskp2/correlators/A100.24_L24_T48_beta190_mul0100_musig150_mudel190_kappa1632550/ev120/liuming/",
            "/hiskp2/correlators/B25.32/christopher/",
            "/hiskp2/correlators/B35.32/liuming/",
            "/hiskp2/correlators/B35.48/liuming/",
            "/hiskp2/correlators/B55.32_L32_T64_beta195_mul0055_musig135_mudel170_kappa1612360/ev220/liuming/",
            "/hiskp2/correlators/B85.24/liuming/",
            "/hiskp2/correlators/D15.48/liuming/",
            "", # D30.48 not calculated yet
            "/hiskp2/correlators/D45.32_L32_T64_beta210_mul0045_musig0937_mudel1077_kappa1563150/ev220/liuming/"]

    d2 = np.dot(d,d)
    suffix="%s_TP%d.npy" % (lattice, d2)
    if not verbose:
        print("reading data")
    if readnew:
        if verbose:
            print("reading files:")
            for f in pilist:
                print(f)
        corr = ana.read_data_ascii("".join((path[ens], pilist[0])))
        pi_data = ana.sym_and_boot(corr, nsamples)
        ana.write_data(pi_data, "%s/pi_data_%s" % (datafolder, suffix))
    else:
        if verbose:
            print("reading numpy data")
        pi_data = ana.read_data("%s/pi_data_%s" % (datafolder, suffix))
    if verbose:
        print("data shapes")
        print(pi_data.shape)
    return pi_data

def fit_single_pion(pi_data, lo, up, fmin, pars, pionfit, tmin, lattice, d,
                    label, plotfolder, datafolder, newfit=True, verbose=True):
    """Fit the correlation function for the single pion.

    Args:
        pi_data: the correlation function
        lo, up: lower and upper bound for the fitranges
        fmin: minimal number of fitpoints in the fitranges
        pars: the start parameters for the fit
        pionfit: fit function for the correlator
        tmin: minimum x to plot
        lattice: the name of the lattice
        d: the total momentum vector
        label: label for the plots
        plotfolder: path to save the plots
        datafolder: path to save the fit results
        newfit: do the fit, if false read data from disk
        verbose: amount of information written on screen

    Returns:
        pi: the resulting parameters from the fit
        chi2: the chi^2 of each fit
        pvals: the p-values of each fit
        fitranges: the used fitranges
    """
    d2 = np.dot(d, d)
    fname = "%s/fit_results_%s_TP%d.npz" % (datafolder, lattice, d2)
    if not verbose:
        print("fitting single pion")
    if newfit:
        if verbose:
            print("new fit")
            print(pi_data.shape)
        pionranges = np.asarray(ana.set_fit_interval(pi_data, lo, up, fmin))
        if verbose:
            print(pionranges.shape)
        pi, chi2, pvals = ana.genfit(pi_data, pionranges, pionfit, pars,
                                    olddata=fname, verbose=verbose)
        ana.write_fitresults(fname, pionranges, pi, chi2, pvals)
        ana.genplot(pi_data, pi, pvals, pionranges, pionfit, tmin, lattice, d,
                    label, plotfolder, "pion_mass", verbose=verbose)
    else:
        if verbose:
            ("reading fit data")
        pionranges, pi, chi2, pvals = ana.read_fitresults(fname)
        ana.genplot(pi_data, pi, pvals, pionranges, pionfit, tmin, lattice, d,
                    label, plotfolder, "pion_mass", verbose=verbose)

    if verbose:
        print("fit infos")
        for p in pi:
            print(p.shape)
    return pi, chi2, pvals, pionranges


def fit_corr_ranges(data, loborder, upborder, intervallsize, fitfunc, 
                    start_params, tmin, lattice, d, verbose=True):
    """Fits a correlation funktion for all intervalls in a specified range.
    The function takes a bootstrapped matrix of principal correlators (solution 
    of the GEVP). It fits the correlation function on every intervall in the 
    range between low and up.

    Args:
        data: A numpy array with three axis. The first axis is the bootstrap 
              sample number, the second axis is the time, the third axis is 
              the eigenvalue numbers. 
        loborder: The lower border for the intervalls.
        upborder: The upper border for the intervalls.
        intervallsize: Minimal number of points fitted to.
        fitfunc: Pretty self-explanatory...
        start_params: The starting parameters for the fit function.
        tmin: Lower bound of the plot.
        lattice: The name of the lattice, used for the output file.
        d:    The total momentum of the reaction.

    Returns:
        res:  The fitted parameters on every bootstrapsample.
        chi2: The chi^2 (without dividing by d.o.f) on every bootstrapsample.
        pval: The p value indicating the quality of the fit.
    """

    label=["corr. fct. fit", "time", "C(t)"]
    path="./plots/"
    plotlabel="corr"
    d2 = np.dot(d, d)
    # construct all intervalls between loborder and upborder and call genfit
    # with the interval as parameter. The intervalls are duplicated, as genfit
    # expects a intervall for each principal correlator
    # TODO: change res to list of np-array with an array for every principal 
    # correlator
    fit_intervalls = ana.set_fit_interval(data, loborder, upborder, intervallsize)
    res, chi2, pval = ana.genfit(data, fit_intervalls, fitfunc, start_params)
#                                 tmin, lattice, d, label, path, plotlabel, 
#                                 verbose)
#    cm.write_corr_matrix(res, "./raw_data/corr_fit_res_rho_%s_TP%d.npy" % (
#                   lattice, d2))
#    cm.write_corr_matrix(chi2, "./raw_data/corr_fit_chi2_rho_%s_TP%d.npy" % (
#                   lattice, d2))
#    cm.write_corr_matrix(pval, "./raw_data/corr_fit_pval_rho_%s_TP%d.npy" % (
#                         lattice, d2))
    return res, chi2, pval

def fit_corr(data, lolist, uplist, fitfunc, start_params, tmin, lattice, d,
             verbose=True):
    """Fit a correlation function.
    """
    label=["corr. fct. fit", "time", "C(t)"]
    path="./plots/"
    plotlabel="corr"
    d2 = np.dot(d, d)
    res, chi2, pval = ana.genfit(data, lolist, uplist, fitfunc, start_params,
        tmin, lattice, d, label, path, plotlabel, verbose)
    ana.write_data(res, "./raw_data/corr_fit_res_rho_%s_TP%d.npy"%(lattice,d2))
    ana.write_data(chi2, "./raw_data/corr_fit_chi2_rho_%s_TP%d.npy"%(lattice,d2))
    ana.write_data(pval, "./raw_data/corr_fit_pval_rho_%s_TP%d.npy"%(lattice,d2))
    return res, chi2, pval


def fit_mass(data, lolist, uplist, fitfunc, start_params, tmin, lattice, d,
             verbose=True):
    """Calculate and fit a mass function.
    """
    label=["mass fit", "time", "C(t)"]
    path="./plots/"
    plotlabel="mass"
    d2 = np.dot(d, d)
    mass, mmass, dmass = ana.compute_mass(data, False)
    res, chi2, pval = ana.genfit(mass, lolist, uplist, fitfunc, start_params,
        tmin, lattice, d, label, path, plotlabel, verbose)
    ana.write_data(res, "./raw_data/mass_fit_res_rho_%s_TP%d.npy"%(lattice,d2))
    ana.write_data(chi2, "./raw_data/mass_fit_chi2_rho_%s_TP%d.npy"%(lattice,d2))
    ana.write_data(pval, "./raw_data/mass_fit_pval_rho_%s_TP%d.npy"%(lattice,d2))
    return res, chi2, pval

def read_fit_corr(lattice, d):
    """Read a previously saved fit.
    """
    print("reading correlation fit data")
    d2 = np.dot(d, d)
    res = ana.read_data("./raw_data/corr_fit_res_rho_%s_TP%d.npy"%(lattice,d2))
    chi2 = ana.read_data("./raw_data/corr_fit_chi2_rho_%s_TP%d.npy"%(lattice,d2))
    pval = ana.read_data("./raw_data/corr_fit_pval_rho_%s_TP%d.npy"%(lattice,d2))
    return res, chi2, pval

def read_fit_mass(lattice, d):
    """Read a previously saved fit.
    """
    print("reading mass fit data")
    d2 = np.dot(d, d)
    res = ana.read_data("./raw_data/mass_fit_res_rho_%s_TP%d.npy"%(lattice,d2))
    chi2 = ana.read_data("./raw_data/mass_fit_chi2_rho_%s_TP%d.npy"%(lattice,d2))
    pval = ana.read_data("./raw_data/mass_fit_pval_rho_%s_TP%d.npy"%(lattice,d2))
    return res, chi2, pval

def calc_error(data, pvals, d, lattice, label, path=".plots/", 
               plotlabel="", plot=False):

    """Calculates the statistical and systematic error of an np-array of 
    fit results on bootstrap samples of a quantity and the corresponding 
    p-values.

    Args:
        data: A numpy array with two axis. The first axis is the bootstrap 
              sample number, the second axis is the fit intervall number.
        pvals: The p value indicating the quality of the fit. Dimensions
              must be the same as for data.
        d:    The total momentum of the reaction.
        lattice: The name of the lattice, used for the output file.
        label: Labels for the title and the axis.
        path: Path to the saving place of the plot.
        plotlabel: Label for the plot file.
        plot: Flag determining whether result shall be plotted or not.

    Returns:
        res: The weighted median value on the original data
        res_std: The standard deviation derived from the deviation of 
              medians on the bootstrapped data.
        res_syst: 1 sigma systematic uncertainty is the difference 
              res - 16%-quantile or 84%-quantile - res respectively
    """
    d2 = np.dot(d, d)

    data_std = np.empty([data.shape[1]], dtype=float)
    data_weight = np.empty([data.shape[1]], dtype=float)

    res = np.empty([data.shape[0]], dtype=float)
    res_syst = np.empty([2], dtype=float)

    # calculate the standard deviation of the bootstrap samples for every 
    # chosen fit intervall
    data_std = np.std(data, axis=0)
    # use that and the p-values to calculate the weight of the fit for every 
    # chosen interval
    data_weight = (1. - 2. * np.fabs(pvals[0] - 0.5) *
                  np.amin(data_std)/data_std)**2

    # draw original data as histogram
    if plot:
        ana.plot_histogram(data[0], data_weight, lattice, d, label, 
                           path, plotlabel)

    # using the weights, calculate the median over all fit intervalls for
    # every bootstrap sample.
    for _i in range(0, data.shape[0]):
        res[_i] = ana.weighted_quantile(data[_i], data_weight, 0.5)
    # the statistical error is the standard deviation of the medians over
    # the bootstrap samples.
    res_std = np.std(res)
    # the systematic error is given by difference between the median on the 
    # original data and the 16%- or 84%-quantile respectively
    res_syst[0] = res[0] - ana.weighted_quantile(data[0], data_weight, 0.16)
    res_syst[1] = ana.weighted_quantile(data[0], data_weight, 0.84) - res[0]

    # only median on original data is of interest later
    return res[0], res_std, res_syst

def ensure_dir(f):
    d = os.path.dirname(f)
    if not os.path.exists(d):
          os.makedirs(d)

def calc_phaseshift(data, pvals, L, d, lattice, mpi, verbose=True):
    """Calculates the phaseshift from fit data.

    Args:
        data: A list of numpy arrays with 3 axes. The first axis is the 
              bootstrap sampe number, the second axis is the number of
              the fit parameter to use. The third axis is the fit intervall
              number.
        pvals: The p value indicating the quality of the fit. Dimensions
              must be the same as for data.
        L:    The spatial extent of the lattice.
        d:    The total momentum of the system.
        lattice: The name of the lattice.
        mpi:  The pion mass of the lattice.

    Returns:
    """
    d2 = np.dot(d, d)
    ncorr = len(data)

    # result for weighted median. data.shape[1] is the number of the 
    # gevp-eigenvalue
    meandata = np.zeros((ncorr, 4))
    # result for statistical error
    statdata = np.zeros_like(meandata)
    # result for systematic error. Additional 2 because asymetric.
    systdata = np.zeros((2, ncorr, 4))

    # treat every principal correlator seperately
    for _i in range(ncorr):
        # the calculations are carried through on every bootstrap sample and 
        # median as well as errors are calculated directly from the 
        # corresponding samples.

        if verbose:
            print("calculating CM energy")
        # data[:,1] is the fit data for the energy fit parameter. The 
        # amplitude is neglected.
        gamma, Ecm = ana.calc_Ecm(data[_i][:,1], L, d)
        if verbose:
            print("calculating q^2")
        q2 = ana.calc_q2(Ecm, mpi, L)
#        print q2.shape()
#        print q2[q2[0]>0]
#        if verbose:
#            print("calculating delta")
#        delta, tandelta, sindelta = ana.calculate_delta(q2, gamma, d)
#
#        f = "./refined_data/%s/%s_Ecm_pc_%d_mv_%d_mpi_%lf" % (lattice[:-3], lattice, _i, d2, mpi)
#        ensure_dir(f)
#        np.save(f, Ecm)
#        f = "./refined_data/%s/%s_delta_pc_%d_mv_%d_mpi_%lf" % (lattice[:-3], lattice, _i, d2, mpi)
#        ensure_dir(f)
#        np.save(f, delta)
#        f = "./refined_data/%s/%s_pvals_pc_%d_mv_%d_mpi_%lf" % (lattice[:-3], lattice, _i, d2, mpi)
#        ensure_dir(f)
#        np.save(f, pvals[_i])

        if verbose:
            print("calculating delta")

        print q2.shape

        q2 = ma.masked_less(q2,0)
        Ecm = ma.array(Ecm, mask=q2.mask)
        gamma = ma.array(gamma, mask=q2.mask)

#        print pvals[_i].shape
        pvals_i = ma.array(pvals[_i], mask=q2.mask)

        q2 = ma.compress_cols(q2)
        print q2.shape
        Ecm = ma.compress_cols(Ecm)
#        print Ecm.shape
        gamma = ma.compress_cols(gamma)
#        print gamma.shape
        pvals_i = ma.compress_cols(pvals_i)
#        pvals = pvals[_i]
#        print pvals.shape
        delta, tandelta, sindelta = ana.calculate_delta(q2, gamma, d)

        f = "./refined_data/%s/%s_Ecm_pc_%d_mv_%d_mpi_%lf" % (lattice[:-3], lattice, _i, d2, mpi)
        ensure_dir(f)
        np.save(f, Ecm)
        f = "./refined_data/%s/%s_delta_pc_%d_mv_%d_mpi_%lf" % (lattice[:-3], lattice, _i, d2, mpi)
        ensure_dir(f)
        np.save(f, delta)
        f = "./refined_data/%s/%s_pvals_pc_%d_mv_%d_mpi_%lf" % (lattice[:-3], lattice, _i, d2, mpi)
        ensure_dir(f)
        np.save(f, pvals_i)


        # data, gamma, Ecm, q2, delta, tandelta are all coded to have the same 
        # shape. calc_error can be used analogeously to obtain weighted median,
        # statistical and systematic error.

        # for Ecm a histogram ist plotted in addition to calculating the 
        # systematic error
        path="./plots/"

        plotlabel = 'hist_Ecm_%d' % _i
#        label = ["", "", "principal correlator"]
        label = ["a", "b", "c"]
        meandata[_i,0], statdata[_i,0], systdata[:,_i,0] = calc_error(Ecm, 
            pvals_i, d, lattice, label, path, plotlabel, True)

        plotlabel = 'hist_delta_%d' % _i
#        label = ["", "", "principal correlator"]
        meandata[_i,1], statdata[_i,1], systdata[:,_i,1] = calc_error(delta, 
            pvals_i, d, lattice, label, path, plotlabel, True)

        plotlabel = 'hist_tandelta_%d' % _i
#        label = ["", "", "principal correlator"]
        meandata[_i,2], statdata[_i,2], systdata[:,_i,2] = calc_error(tandelta, 
            pvals_i, d, lattice, label, path, plotlabel, True)

        plotlabel = 'hist_sindelta_%d' % _i
#        label = ["", "", "principal correlator"]
        meandata[_i,3], statdata[_i,3], systdata[:,_i,3] = calc_error(sindelta, 
            pvals_i, d, lattice, label, path, plotlabel, True)

    return meandata, statdata, systdata

def setup_lattice(lattice, d):
    """Setup of the pion mass, lattice size and fit ranges.
    """
    # the general settings don't make sense!
    mpi=0.11111 
    L=24
    T=48
    loborder = np.array((7,7))
    upborder = np.array((16, 16))
    ### setting for each lattice and moving frame
    if lattice == "A30.32": ###################################################
        mpi=0.1239
        L=32
        T=64
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((9, 7))
#            upborder=np.array((29, 25))
            upborder=np.array((21, 21))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((9, 7))
#            upborder=np.array((31, 23))
            upborder=np.array((20, 18))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((9, 7))
#            upborder=np.array((24, 20))
            upborder=np.array((19, 17))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((8, 6))
#            upborder=np.array((21, 14))
            upborder=np.array((18, 14))
        elif np.array_equal(d, np.array([2., 0., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((17, 17))
    elif lattice == "A40.20": #################################################
        mpi=0.14
        L=20
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((5, 5))
            upborder=np.array((20, 15))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((5, 5))
            upborder=np.array((20, 17))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((5, 5))
            upborder=np.array((18, 12))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((5, 5))
            upborder=np.array((15, 10)) #11
        elif np.array_equal(d, np.array([0., 0., 2.])):
            loborder=np.array((5, 5))
            upborder=np.array((12, 11))
    elif lattice == "A40.24": #################################################
        mpi=0.14463
        L=24
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((5, 5))
#            upborder=np.array((23, 16))
            upborder=np.array((23, 16))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((5, 5))
#            upborder=np.array((23, 18))
            upborder=np.array((23, 18))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((5, 5))
#            upborder=np.array((22, 17))
            upborder=np.array((22, 17))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((5, 5))
            upborder=np.array((20, 13))
#            upborder=np.array((17, 14))
        elif np.array_equal(d, np.array([0., 0., 2.])):
            loborder=np.array((5, 5))
            upborder=np.array((15, 14))
    elif lattice == "A40.32": #################################################
        mpi=0.14151
        L=32
        T=64
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((5, 5))
            upborder=np.array((29, 25))
#            upborder=np.array((21, 21))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((5, 5))
            upborder=np.array((31, 23))
#            upborder=np.array((20, 18))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((5, 5))
            upborder=np.array((24, 20))
#            upborder=np.array((19, 17))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((5, 5))
            upborder=np.array((21, 14))
#            upborder=np.array((18, 14))
        elif np.array_equal(d, np.array([2., 0., 0.])):
            loborder=np.array((5, 5))
            upborder=np.array((17, 15))
#
#    elif lattice == "A40.20": #################################################
#        mpi=0.14
#        L=20
#        T=48
#        if np.array_equal(d, np.array([0., 0., 0.])):
#            loborder=np.array((7, 5))
#            upborder=np.array((16, 15))
#        elif np.array_equal(d, np.array([0., 0., 1.])):
#            loborder=np.array((7, 5))
#            upborder=np.array((15, 17))
#        elif np.array_equal(d, np.array([1., 1., 0.])):
#            loborder=np.array((7, 5))
#            upborder=np.array((15, 12))
#        elif np.array_equal(d, np.array([1., 1., 1.])):
#            loborder=np.array((6, 5))
#            upborder=np.array((15, 12)) #11
#        elif np.array_equal(d, np.array([0., 0., 2.])):
#            loborder=np.array((5, 5))
#            upborder=np.array((12, 11))
#    elif lattice == "A40.24": #################################################
#        mpi=0.14463
#        L=24
#        T=48
#        if np.array_equal(d, np.array([0., 0., 0.])):
#            loborder=np.array((7, 5))
##            upborder=np.array((23, 16))
#            upborder=np.array((20, 17))
#        elif np.array_equal(d, np.array([0., 0., 1.])):
#            loborder=np.array((7, 5))
##            upborder=np.array((23, 18))
#            upborder=np.array((19, 16))
#        elif np.array_equal(d, np.array([1., 1., 0.])):
#            loborder=np.array((7, 5))
##            upborder=np.array((22, 17))
#            upborder=np.array((18, 15))
#        elif np.array_equal(d, np.array([1., 1., 1.])):
#            loborder=np.array((6, 5))
##            upborder=np.array((20, 13))
#            upborder=np.array((17, 14))
#        elif np.array_equal(d, np.array([0., 0., 2.])):
#            loborder=np.array((5, 5))
#            upborder=np.array((16, 14))
#    elif lattice == "A40.32": #################################################
#        mpi=0.14151
#        L=32
#        T=64
#        if np.array_equal(d, np.array([0., 0., 0.])):
#            loborder=np.array((9, 7))
##            upborder=np.array((29, 25))
#            upborder=np.array((21, 21))
#        elif np.array_equal(d, np.array([0., 0., 1.])):
#            loborder=np.array((9, 7))
##            upborder=np.array((31, 23))
#            upborder=np.array((20, 18))
#        elif np.array_equal(d, np.array([1., 1., 0.])):
#            loborder=np.array((9, 7))
##            upborder=np.array((24, 20))
#            upborder=np.array((19, 17))
#        elif np.array_equal(d, np.array([1., 1., 1.])):
#            loborder=np.array((8, 6))
##            upborder=np.array((21, 14))
#            upborder=np.array((18, 14))
#        elif np.array_equal(d, np.array([2., 0., 0.])):
#            loborder=np.array((7, 5))
#            upborder=np.array((17, 17))
    elif lattice == "A60.24": #################################################
        mpi=0.1733
        L=24
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((19, 16))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((7, 5))
            upborder=np.array((18, 15))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((17, 14))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((6, 5))
            upborder=np.array((17, 14))
        elif np.array_equal(d, np.array([0., 0., 2.])):
            loborder=np.array((5, 5))
            upborder=np.array((16, 14))
    elif lattice == "A80.24": #################################################
        mpi=0.1993
        L=24
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((19, 16))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((7, 5))
            upborder=np.array((18, 15))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((17, 14))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((6, 5))
            upborder=np.array((17, 14))
        elif np.array_equal(d, np.array([0., 0., 2.])):
            loborder=np.array((5, 5))
            upborder=np.array((16, 14))
    elif lattice == "A100.24": #################################################
        mpi=0.2224
        L=24
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((19, 16))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((7, 5))
            upborder=np.array((18, 15))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((17, 14))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((6, 5))
            upborder=np.array((17, 14))
        elif np.array_equal(d, np.array([0., 0., 2.])):
            loborder=np.array((5, 5))
            upborder=np.array((16, 14))
    elif lattice == "B55.32": ##################################################
        mpi=0.15518
        L=32
        T=64
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((9, 7))
#            upborder=np.array((29, 25))
            upborder=np.array((21, 21))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((9, 7))
#            upborder=np.array((31, 23))
            upborder=np.array((20, 18))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((9, 7))
#            upborder=np.array((24, 20))
            upborder=np.array((19, 17))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((8, 6))
#            upborder=np.array((21, 14))
            upborder=np.array((18, 14))
        elif np.array_equal(d, np.array([2., 0., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((17, 17))
    elif lattice == "D45.32": ##################################################
        mpi=0.12087
        L=32
        T=64
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((9, 7))
#            upborder=np.array((29, 25))
            upborder=np.array((17, 16))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((9, 7))
#            upborder=np.array((31, 23))
            upborder=np.array((17, 16))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((9, 7))
#            upborder=np.array((24, 20))
            upborder=np.array((16, 15))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((8, 7))
#            upborder=np.array((21, 14))
            upborder=np.array((16, 15))
        elif np.array_equal(d, np.array([2., 0., 0.])):
            loborder=np.array((7, 7))
            upborder=np.array((15, 15))

    # for testing -> three intervalls on A40.24 TP0
#    loborder = np.array((7, 7))
#    upborder = np.array((23, 23))

    return mpi, L, T, loborder, upborder

def analyse_pi(ens, ensemble, datafolder, plotfolder):
    """pi-pi scattering analysis for I=2.

    Args:
        ensemble: the ensemble to work on
        datafolder: where to store raw data
        plotfolder: where to store the plots
    """
    ## define main variables
    # flags for the different parts
    readnewdata=True
    fitsinglepion=True
    calculategevp=True
    # verbose prints all the shaped of the different arrays
    verbose=False
    nsamples = 1500 # number of bootstrap samples
    tmin = 1 # for the GEVP

    ## other variables
    # total momentum
    d = ensemble.get_data("d")
    d2 = np.dot(d, d)
    L = ensemble.L
    T = ensemble.T
    T2 = ensemble.T2
    gmax = ensemble.get_data("gmax")
    lattice = ensemble.name
    slist = ensemble.get_data("s")
    # file list
    pilist = ["pi_corr_p%d.dat" % d2 ]
    # fit functions
    massfit = lambda p,t : p

    # label for the plots
    label_pion = ["single pion", "time", "am$_{\pi}$(t)", "data", ""]
    label_ratio = ["ratio", "time", "R(t)", "data", ""]
    # lower and upper fit ranges for the different correlators
    lo_pion = [8]
    up_pion = [T2]
    if (L == 24) or (L==20):
        lo_ratio = [6, 6, 4, 4, 4]
        up_ratio = [20, 20, 7, 7, 7]
        # minimal number of points in each fit
        fmin = 4
    elif L == 32:
        lo_pion = [10]
        lo_ratio = [8, 8, 4, 4, 4]
        up_ratio = [26, 26, 7, 7, 7]
        # minimal number of points in each fit
        fmin = 6
    elif L == 48:
        lo_pion = [12]
        lo_ratio = [10, 16, 4, 4, 4]
        up_ratio = [40, 37, 7, 7, 7]
        # minimal number of points in each fit
        fmin = 7
    else:
        print("no fit ranges given for L = %d" % L)
        sys.exit(-1)
    if lattice == "A40.24":
        lo_ratio = [8, 10, 4, 4, 4]
        up_ratio = [20, 20, 7, 7, 7]
        
    # initial parameters for the fits
    par_mass = [0.2]
    par_pion = [100., 0.2]
    par_ratio = [0.5, 0.01]

    ## read in data
    pi_data = read_pi(ens, pilist, datafolder, nsamples, lattice, d, 
                        readnew=readnewdata)

    # fit the mass
    ## calculate effective mass of the pion
    pimass, pimmass, pidmass = ana.compute_mass(pi_data)
    lab = lattice
    # fit single pion effective mass function
    pi, pichi2, pipvals, pionranges = fit_single_pion(pimass, lo_pion, up_pion, 
        fmin, par_mass, massfit, tmin, lattice, d, label_pion, plotfolder,
        datafolder, newfit=fitsinglepion)
    # calculate statistic and systematic error of the pion
    piplotname="".join(("pion_mass_", lattice))
    mpi, dmpi_stat, dmpi_syst, weights_mpi = ana.sys_error(pi, pipvals, d, 
                                                 piplotname, path=plotfolder)
    if verbose == False:
        print("single pion")
        print(len(weights_mpi))
        for p in weights_mpi:
            print(p.shape)
    print("mpi with errors")
    for p, dp, ddp in zip(mpi, dmpi_stat, dmpi_syst):
        print("%.5f +- %.5f -%.5f +%.5f" % (p, dp, ddp[0], ddp[1]))

    return pi, pichi2, pipvals


#def analyse(lattice="A40.24", d=np.array([0., 0., 0.]), verbose=True):
def analyse(ensemble, datafolder, plotfolder):
    #######################################################
    ## definition of main variables
    nbsamples = 400 # number of bootstrap samples
    tmin=1 # t0 for the GEVP calculation
    #d = np.array([0., 0., 1.]) # total momemtum of the system
    #lattice="A40.24" # lattice to analyse
    #######################################################
    # these variables are overwritten
#    T = ensemble.get_data("T")
#    L = ensemble.get_data("L")
    T = ensemble.T
    L = ensemble.L

#    T=48
#    L=24
    mpi=0.14463 # A40.24 from Carstens pipi I=2 analysis
    #######################################################
    ## define the fit function and start parameters
    #fitfunc = lambda p,t: p[0]*np.cosh((T/2.0-t)*p[1])
    #start_params = [0.005, -0.5]
    #fitfunc = lambda p,t: p[0]*np.exp(-p[1]*t)
    #start_params = [1.0, 0.5]
    #fitfunc = lambda p,t: np.exp(-p[0]*t)
    #start_params = [0.5]
    fitfunc = lambda p,t: 10e6 if p[1] < 0. else \
              0.5*p[0]*p[0]*(np.exp(-p[1]*t) + np.exp(-p[1]*(T-t)))
    start_params = [1, 0.5]
    massfunc = lambda p, t: p
    mass_sparams = [0.5]
    #######################################################
    ## setting variables
    # TODO: error messages if something is ill-defined -> unit test?
    d = ensemble.get_data("d")
    print d
    d2 = np.dot(d, d)

    lattice = ensemble.name
    path = ensemble.get_data("path")

    filelist = ["rho_corr_TP%d_00" % d2, "rho_corr_TP%d_01" % d2,\
                "rho_corr_TP%d_01" % d2, "rho_corr_TP%d_11" % d2]
    #filelist = ["rho_corr_TP%d_00" % d2]
    mpi, L, T, loborder, upborder = setup_lattice(lattice, d)
    print mpi, L, T
    ## print what is being calculated
    print("lattice %s, TP %d" % (lattice, d2))

    ## read in new data
    gevp_mat = read_new_data(nbsamples, path, filelist, tmin, lattice, d2)

    ## read in solution of GEVP
    #gevp_mat = ana.read_data("../raw_data/gevp_mat_rho_%s_TP%d.npy" % (lattice, d2))

    ## fit correlation function
    # 7-np.sqrt(d2) is empirical. For high momenta, there are no plateaus as long as
    # for the lower ones before running into exponential error growth.
    # use 7 for 20 and 24 TP0-2, 6 TP3-4, 9 for 32 TP0-2, 8 TP3-4
    res, chi2, pvals = fit_corr_ranges(gevp_mat, loborder, upborder, 
#                                       8, fitfunc, 
                                       7-np.sqrt(d2).astype(int), fitfunc, 
#                                       10, fitfunc, 
                                       start_params, tmin, lattice, d, True)
    #res, chi2, pvals = read_fit_corr(lattice, d)
    #return

    ## fit mass function NOT YET TESTED
    #massres, masschi2, masspvals = fit_mass(gevp_mat, lolist, uplist, massfunc,
    #    mass_sparams, tmin, lattice, d)
    #massres1, masschi21, masspvals1 = read_fit_mass(lattice, d)
    #print(np.array_equal(massres, massres1))

    ## calculate phaseshift
    ## TODO: Why does res[:][:,1] not have the right dimensions. Fix the fit 
    ## parameter to value for the energy
    meandata, statdata, systdata = calc_phaseshift(res, pvals, L, d, lattice, mpi)

    # print data
    print_results(meandata, statdata, systdata)
    filename="./data_mean_%s_TP%d.dat" % (lattice, d2)
    write_results(meandata, statdata, systdata, filename)

    return

def main():
#    d0 = np.array([0., 0., 0.]) # total momentum of the system
#    d1 = np.array([0., 0., 1.]) # total momentum of the system
#    d2 = np.array([1., 1., 0.]) # total momentum of the system
#    d3 = np.array([1., 1., 1.]) # total momentum of the system
#    d4 = np.array([0., 0., 2.]) # total momentum of the system

    momenta=[np.array([0., 0., 0.]), np.array([0., 0., 1.]), 
             np.array([1., 1., 0.]), np.array([1., 1., 1.]),
             np.array([0., 0., 2.])]

    lattices=["A30.32", "A40.20", "A40.24", "A40.32", "A60.24",
              "A80.24", "A100.24", "B25.32", "B35.32", "B35.48",
              "B55.32", "B85.24", "D15.48", "D30.48", "D45.32"]

    if len(sys.argv) < 2:
        ens = 2
    elif int(sys.argv[1]) >= len(lattices):
        print("ensemble not known, the following are known.")
        print(lattices)
        sys.exit(-11)
    else:
        ens = int(sys.argv[1])

#    if lattices[ens] == "D30.48":
#        print("D30.48 not calculated yet")
#        sys.exit(-11)

    #TODO: s is a terrible name for a 3-momentum
    if len(sys.argv) < 3:
        s = momenta[0]
    elif int(sys.argv[2]) <= 4:
        s = momenta[int(sys.argv[2])]
    else:
        print("shift of %d does not make sense" % (sys.argv[2]))
        sys.exit(-11)

    s2 = np.dot(s,s)


    #A30
    #analyse(lattices[0], d0) 
    #analyse(lattices[0], d1)
    #analyse(lattices[0], d2)
    #analyse(lattices[0], d3)
    #analyse(lattices[0], d4)

    #A40
    #analyse(lattices[1], d0) 
    #analyse(lattices[1], d1)
    #analyse(lattices[1], d2)
    #analyse(lattices[1], d3)
    #analyse(lattices[1], d4)

    #analyse(lattices[2], d0)
    #analyse(lattices[2], d1)
    #analyse(lattices[2], d2)
    #analyse(lattices[2], d3)
    #analyse(lattices[2], d4)

    #analyse(lattices[3], d0)
    #analyse(lattices[3], d1)
    #analyse(lattices[3], d2)
    #analyse(lattices[3], d3)
    #analyse(lattices[3], d4)

    #A60
    #analyse(lattices[4], d0)
    #analyse(lattices[4], d1)
    #analyse(lattices[4], d2)
    #analyse(lattices[4], d3)
    #analyse(lattices[4], d4)

    #A80
    #analyse(lattices[5], d0)
    #analyse(lattices[5], d1)
    #analyse(lattices[5], d2)
    #analyse(lattices[5], d3)
    #analyse(lattices[5], d4)

    #A100
    #analyse(lattices[6], d0)
    #analyse(lattices[6], d1)
    #analyse(lattices[6], d2)
    #analyse(lattices[6], d3)
    #analyse(lattices[6], d4)

    #B55 
    #analyse(lattices[7], d0)
    #analyse(lattices[7], d1)
    #analyse(lattices[7], d2)
    #analyse(lattices[7], d3)
    #analyse(lattices[7], d4)

    #D45
    #analyse(lattices[8], d0)
    #analyse(lattices[8], d1)
    #analyse(lattices[8], d2)
    #analyse(lattices[8], d3)
    #analyse(lattices[8], d4)

    #path="".join(("/hiskp2/jost/data/rho_analyse/", lattice, "/"))

    datafolder = "./raw_data/"
    plotfolder = "./plots/"

    # t_min for gevp
    gmax = [3, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]

    ensembles = []
    for i, lat in enumerate(lattices):
        #cut lattice size from lattice name
        L = int(lattices[ens][-2:])
        T = 2*L
        if L == 20:
            T=48
        path="".join(("/hiskp2/werner/analyse/" + lat + "_mv%d" % s2 + 
                      "/Analysis/"))
    
        # init lattice data structure. reference lattice name, L and T by 
        # ensembles.name, ensembles.L, ensembles.T
        ensembles.append(ana.LatticeEnsemble(lat, L, T))
        # write path into ensemble. reference by ensemble.get_data("path")
        ensembles[-1].add_data("path", path)
        # write gmax into ensemble. reference by ensemble.get_data("gmax")
        ensembles[-1].add_data("gmax", gmax[i])
        #TODO: ask Christian what s is
        # write ? into ensemble. reference by ensemble.get_data("s")
        ensembles[-1].add_data("s", [0,1])
        # write momentum into ensemble. reference by ensemble.get_data("d")
        ensembles[-1].add_data("d", s)

#    print ensembles[2]

    print("calculating %s" % (lattices[ens]))
#    pi, pichi2, pipvals = analyse_pi(ens, ensembles[ens], datafolder, plotfolder)
    analyse(ensembles[ens], datafolder, plotfolder)
    
    return

# make this script importable, according to the Google Python Style Guide
if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\nKeyboard Interrupt, exiting...")
