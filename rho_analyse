#!/hadron/knippsch/Enthought/Canopy_64bit/User/bin/python
##!/usr/bin/python
################################################################################
#
# Author: Christian Jost (jost@hiskp.uni-bonn.de)
# Date:   Februar 2015
#
# Copyright (C) 2015 Christian Jost
# 
# This program is free software: you can redistribute it and/or modify it under 
# the terms of the GNU General Public License as published by the Free Software 
# Foundation, either version 3 of the License, or (at your option) any later 
# version.
# 
# This program is distributed in the hope that it will be useful, but WITHOUT 
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS 
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with tmLQCD. If not, see <http://www.gnu.org/licenses/>.
#
################################################################################
#
# Function: This is the start of the eta/eta' analysis program
#
# For informations on input parameters see the description of the function.
#
################################################################################

import os
import numpy as np

import analysis as ana

def print_results(data, staterror, systerror):
    """Prints the results to screen
    """
    print("E dE - +  delta ddelta - +  tan dtan - +  sin2 dsin2 - +")
    for _i in range(data.shape[0]):
        print("%.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf  %.7lf %.7lf  %.7lf %.7lf" % (
              data[_i,0], staterror[_i,0], systerror[0,_i,0], systerror[1,_i,0],
              data[_i,1], staterror[_i,1], systerror[0,_i,1], systerror[1,_i,1],
              data[_i,2], staterror[_i,2], systerror[0,_i,2], systerror[1,_i,2],
              data[_i,3], staterror[_i,3], systerror[0,_i,3], systerror[1,_i,3]))

def write_results(data, staterror, systerror, filename):
    """Writes the results to file.
    """
    # check whether file exists
    if os.path.isfile(filename):
        print(filename + " already exists, overwritting...")
    # open file for writting
    outfile = open(filename, "w")
    outfile.write("E dE - +  delta ddelta - +  tan dtan - +  sin2 dsin2 - +\n")
    for _i in range(data.shape[0]):
        outfile.write("%.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf %.7lf  %.7lf %.7lf  %.7lf %.7lf\n" % (
              data[_i,0], staterror[_i,0], systerror[0,_i,0], systerror[1,_i,0],
              data[_i,1], staterror[_i,1], systerror[0,_i,1], systerror[1,_i,1],
              data[_i,2], staterror[_i,2], systerror[0,_i,2], systerror[1,_i,2],
              data[_i,3], staterror[_i,3], systerror[0,_i,3], systerror[1,_i,3]))

def read_new_data(nbsamples, path, filelist, tmin, lattice, d2, verbose=False):
    """Read in data for a new configuration.
    """
    # read in data for GEVP
    if verbose:
        print("reading data")
    corr_mat = ana.create_corr_matrix(nbsamples, path, filelist)
    ana.write_data(corr_mat, "./raw_data/corr_mat_rho_%s_TP%d.npy"%(lattice,d2))
    # solve the GEVP
    if verbose:
        print("solving GEVP")
    gevp_mat = ana.calculate_gevp(corr_mat, tmin)
    ana.write_data(gevp_mat, "./raw_data/gevp_mat_rho_%s_TP%d.npy"%(lattice,d2))
    # write in ASCII
    ana.write_data_ascii(gevp_mat,"./raw_data/gevp_rho_%s_TP%d.dat"%(lattice,d2))
    return gevp_mat

def fit_corr_ranges(data, loborder, upborder, intervallsize, fitfunc, 
                    start_params, tmin, lattice, d, verbose=True):
    """Fits a correlation funktion for all intervalls in a specified range.
    The function takes a bootstrapped matrix of principal correlators (solution 
    of the GEVP). It fits the correlation function on every intervall in the 
    range between low and up.

    Args:
        data: A numpy array with three axis. The first axis is the bootstrap 
              sample number, the second axis is the time, the third axis is 
              the eigenvalue numbers. 
        loborder: The lower border for the intervalls.
        upborder: The upper border for the intervalls.
        intervallsize: Minimal number of points fitted to.
        fitfunc: Pretty self-explanatory...
        start_params: The starting parameters for the fit function.
        tmin: Lower bound of the plot.
        lattice: The name of the lattice, used for the output file.
        d:    The total momentum of the reaction.

    Returns:
        res:  The fitted parameters on every bootstrapsample.
        chi2: The chi^2 (without dividing by d.o.f) on every bootstrapsample.
        pval: The p value indicating the quality of the fit.
    """

    label=["corr. fct. fit", "time", "C(t)"]
    path="./plots/"
    plotlabel="corr"
    d2 = np.dot(d, d)
    # construct all intervalls between loborder and upborder and call genfit
    # with the interval as parameter. The intervalls are duplicated, as genfit
    # expects a intervall for each principal correlator
    # TODO: change res to list of np-array with an array for every principal 
    # correlator
    fit_intervalls = ana.set_fit_interval(data, loborder, upborder, intervallsize)
    res, chi2, pval = ana.genfit(data, fit_intervalls, fitfunc, start_params, 
                                 tmin, lattice, d, label, path, plotlabel, 
                                 verbose)
#    cm.write_corr_matrix(res, "./raw_data/corr_fit_res_rho_%s_TP%d.npy" % (
#                   lattice, d2))
#    cm.write_corr_matrix(chi2, "./raw_data/corr_fit_chi2_rho_%s_TP%d.npy" % (
#                   lattice, d2))
#    cm.write_corr_matrix(pval, "./raw_data/corr_fit_pval_rho_%s_TP%d.npy" % (
#                         lattice, d2))
    return res, chi2, pval

def fit_corr(data, lolist, uplist, fitfunc, start_params, tmin, lattice, d,
             verbose=True):
    """Fit a correlation function.
    """
    label=["corr. fct. fit", "time", "C(t)"]
    path="./plots/"
    plotlabel="corr"
    d2 = np.dot(d, d)
    res, chi2, pval = ana.genfit(data, lolist, uplist, fitfunc, start_params,
        tmin, lattice, d, label, path, plotlabel, verbose)
    ana.write_data(res, "./raw_data/corr_fit_res_rho_%s_TP%d.npy"%(lattice,d2))
    ana.write_data(chi2, "./raw_data/corr_fit_chi2_rho_%s_TP%d.npy"%(lattice,d2))
    ana.write_data(pval, "./raw_data/corr_fit_pval_rho_%s_TP%d.npy"%(lattice,d2))
    return res, chi2, pval


def fit_mass(data, lolist, uplist, fitfunc, start_params, tmin, lattice, d,
             verbose=True):
    """Calculate and fit a mass function.
    """
    label=["mass fit", "time", "C(t)"]
    path="./plots/"
    plotlabel="mass"
    d2 = np.dot(d, d)
    mass, mmass, dmass = ana.compute_mass(data, False)
    res, chi2, pval = ana.genfit(mass, lolist, uplist, fitfunc, start_params,
        tmin, lattice, d, label, path, plotlabel, verbose)
    ana.write_data(res, "./raw_data/mass_fit_res_rho_%s_TP%d.npy"%(lattice,d2))
    ana.write_data(chi2, "./raw_data/mass_fit_chi2_rho_%s_TP%d.npy"%(lattice,d2))
    ana.write_data(pval, "./raw_data/mass_fit_pval_rho_%s_TP%d.npy"%(lattice,d2))
    return res, chi2, pval

def read_fit_corr(lattice, d):
    """Read a previously saved fit.
    """
    print("reading correlation fit data")
    d2 = np.dot(d, d)
    res = ana.read_data("./raw_data/corr_fit_res_rho_%s_TP%d.npy"%(lattice,d2))
    chi2 = ana.read_data("./raw_data/corr_fit_chi2_rho_%s_TP%d.npy"%(lattice,d2))
    pval = ana.read_data("./raw_data/corr_fit_pval_rho_%s_TP%d.npy"%(lattice,d2))
    return res, chi2, pval

def read_fit_mass(lattice, d):
    """Read a previously saved fit.
    """
    print("reading mass fit data")
    d2 = np.dot(d, d)
    res = ana.read_data("./raw_data/mass_fit_res_rho_%s_TP%d.npy"%(lattice,d2))
    chi2 = ana.read_data("./raw_data/mass_fit_chi2_rho_%s_TP%d.npy"%(lattice,d2))
    pval = ana.read_data("./raw_data/mass_fit_pval_rho_%s_TP%d.npy"%(lattice,d2))
    return res, chi2, pval

def calc_error(data, pvals, d, lattice, label, path=".plots/", 
               plotlabel="", plot=False):

    """Calculates the statistical and systematic error of an np-array of 
    fit results on bootstrap samples of a quantity and the corresponding 
    p-values.

    Args:
        data: A numpy array with two axis. The first axis is the bootstrap 
              sample number, the second axis is the fit intervall number.
        pvals: The p value indicating the quality of the fit. Dimensions
              must be the same as for data.
        d:    The total momentum of the reaction.
        lattice: The name of the lattice, used for the output file.
        label: Labels for the title and the axis.
        path: Path to the saving place of the plot.
        plotlabel: Label for the plot file.
        plot: Flag determining whether result shall be plotted or not.

    Returns:
        res: The weighted median value on the original data
        res_std: The standard deviation derived from the deviation of 
              medians on the bootstrapped data.
        res_syst: 1 sigma systematic uncertainty is the difference 
              res - 16%-quantile or 84%-quantile - res respectively
    """
    d2 = np.dot(d, d)

    data_std = np.empty([data.shape[1]], dtype=float)
    data_weight = np.empty([data.shape[1]], dtype=float)

    res = np.empty([data.shape[0]], dtype=float)
    res_syst = np.empty([2], dtype=float)

    # calculate the standard deviation of the bootstrap samples for every 
    # chosen fit intervall
    data_std = np.std(data, axis=0)
    # use that and the p-values to calculate the weight of the fit for every 
    # chosen interval
    data_weight = (1. - 2. * np.fabs(pvals[0] - 0.5) *
                  np.amin(data_std)/data_std)**2

    # draw original data as histogram
    if plot:
        ana.plot_histogram(data[0], data_weight, lattice, d, label, 
                           path, plotlabel)

    # using the weights, calculate the median over all fit intervalls for
    # every bootstrap sample.
    for _i in range(0, data.shape[0]):
        res[_i] = ana.weighted_quantile(data[_i], data_weight, 0.5)
    # the statistical error is the standard deviation of the medians over
    # the bootstrap samples.
    res_std = np.std(res)
    # the systematic error is given by difference between the median on the 
    # original data and the 16%- or 84%-quantile respectively
    res_syst[0] = res[0] - ana.weighted_quantile(data[0], data_weight, 0.16)
    res_syst[1] = ana.weighted_quantile(data[0], data_weight, 0.84) - res[0]

    # only median on original data is of interest later
    return res[0], res_std, res_syst


def calc_phaseshift(data, pvals, L, d, lattice, mpi, verbose=True):
    """Calculates the phaseshift from fit data.

    Args:
        data: A list of numpy arrays with 3 axes. The first axis is the 
              bootstrap sampe number, the second axis is the number of
              the fit parameter to use. The third axis is the fit intervall
              number.
        pvals: The p value indicating the quality of the fit. Dimensions
              must be the same as for data.
        L:    The spatial extent of the lattice.
        d:    The total momentum of the system.
        lattice: The name of the lattice.
        mpi:  The pion mass of the lattice.

    Returns:
    """
    d2 = np.dot(d, d)
    ncorr = len(data)

    # result for weighted median. data.shape[1] is the number of the 
    # gevp-eigenvalue
    meandata = np.zeros((ncorr, 4))
    # result for statistical error
    statdata = np.zeros_like(meandata)
    # result for systematic error. Additional 2 because asymetric.
    systdata = np.zeros((2, ncorr, 4))

    # treat every principal correlator seperately
    for _i in range(ncorr):
        # the calculations are carried through on every bootstrap sample and 
        # median as well as errors are calculated directly from the 
        # corresponding samples.

        if verbose:
            print("calculating CM energy")
        # data[:,1] is the fit data for the energy fit parameter. The 
        # amplitude is neglected.
        gamma, Ecm = ana.calc_Ecm(data[_i][:,1], L, d)
        if verbose:
            print("calculating q^2")
        q2 = ana.calc_q2(Ecm, mpi, L)
        if verbose:
            print("calculating delta")
        delta, tandelta, sindelta = ana.calculate_delta(q2, gamma, d)

        # data, gamma, Ecm, q2, delta, tandelta are all coded to have the same 
        # shape. calc_error can be used analogeously to obtain weighted median,
        # statistical and systematic error.

        # for Ecm a histogram ist plotted in addition to calculating the 
        # systematic error
        path="./plots/"

        plotlabel = 'hist_Ecm_%d' % _i
#        label = ["", "", "principal correlator"]
        label = ["a", "b", "c"]
        meandata[_i,0], statdata[_i,0], systdata[:,_i,0] = calc_error(Ecm, 
            pvals[_i], d, lattice, label, path, plotlabel, True)

        plotlabel = 'hist_delta_%d' % _i
#        label = ["", "", "principal correlator"]
        meandata[_i,1], statdata[_i,1], systdata[:,_i,1] = calc_error(delta, 
            pvals[_i], d, lattice, label, path, plotlabel, True)

        plotlabel = 'hist_tandelta_%d' % _i
#        label = ["", "", "principal correlator"]
        meandata[_i,2], statdata[_i,2], systdata[:,_i,2] = calc_error(tandelta, 
            pvals[_i], d, lattice, label, path, plotlabel, True)

        plotlabel = 'hist_sindelta_%d' % _i
#        label = ["", "", "principal correlator"]
        meandata[_i,3], statdata[_i,3], systdata[:,_i,3] = calc_error(sindelta, 
            pvals[_i], d, lattice, label, path, plotlabel, True)

    return meandata, statdata, systdata

def setup_lattice(lattice, d):
    """Setup of the pion mass, lattice size and fit ranges.
    """
    # the general settings don't make sense!
    mpi=0.11111 
    L=24
    T=48
    loborder = np.array((7,7))
    upborder = np.array((16, 16))
    ### setting for each lattice and moving frame
    if lattice == "A30.32": ###################################################
        mpi=0.1239
        L=32
        T=64
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((9, 11))
            upborder=np.array((16, 15))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((11, 11))
            upborder=np.array((17, 16))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            print("not yet looked at")
            loborder=np.array((9, 10))
            upborder=np.array((17, 17))
    elif lattice == "A40.20": #################################################
        mpi=0.14
        L=20
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((20, 15))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((7, 5))
            upborder=np.array((20, 17))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((18, 12))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((6, 5))
            upborder=np.array((15, 12)) #11
        elif np.array_equal(d, np.array([0., 0., 2.])):
            loborder=np.array((5, 5))
            upborder=np.array((12, 11))
    elif lattice == "A40.24": #################################################
        mpi=0.14463
        L=24
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((7, 5))
#            upborder=np.array((23, 16))
            upborder=np.array((20, 17))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((7, 5))
#            upborder=np.array((23, 18))
            upborder=np.array((19, 16))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((7, 5))
#            upborder=np.array((22, 17))
            upborder=np.array((18, 15))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((6, 5))
#            upborder=np.array((20, 13))
            upborder=np.array((17, 13))
        elif np.array_equal(d, np.array([0., 0., 2.])):
            loborder=np.array((5, 5))
            upborder=np.array((16, 14))
    elif lattice == "A40.32": #################################################
        mpi=0.14151
        L=32
        T=64
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((9, 7))
#            upborder=np.array((29, 25))
            upborder=np.array((21, 21))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((9, 7))
#            upborder=np.array((31, 23))
            upborder=np.array((20, 18))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((9, 7))
#            upborder=np.array((24, 20))
            upborder=np.array((19, 17))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((8, 6))
#            upborder=np.array((21, 14))
            upborder=np.array((18, 14))
        elif np.array_equal(d, np.array([2., 0., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((17, 17))
    elif lattice == "A60.24": #################################################
        mpi=0.1733
        L=24
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            print("not yet looked at")
            loborder=np.array((12, 7))
            upborder=np.array((16, 17))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            print("not yet looked at")
            loborder=np.array((12, 7))
            upborder=np.array((16, 17))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            print("not yet looked at")
            loborder=np.array((12, 7))
            upborder=np.array((16, 17))
    elif lattice == "A80.24": #################################################
        mpi=0.1993
        L=24
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            print("not yet looked at")
            loborder=np.array((12, 7))
            upborder=np.array((16, 17))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((10, 10))
            upborder=np.array((15, 15))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            print("not yet looked at")
            loborder=np.array((12, 7))
            upborder=np.array((16, 17))
    elif lattice == "A100.24": ################################################
        mpi=0.2224
        L=24
        T=48
        if np.array_equal(d, np.array([0., 0., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((20, 17))
        elif np.array_equal(d, np.array([0., 0., 1.])):
            loborder=np.array((7, 5))
            upborder=np.array((19, 16))
        elif np.array_equal(d, np.array([1., 1., 0.])):
            loborder=np.array((7, 5))
            upborder=np.array((18, 15))
        elif np.array_equal(d, np.array([1., 1., 1.])):
            loborder=np.array((6, 5))
            upborder=np.array((17, 13))
        elif np.array_equal(d, np.array([0., 0., 2.])):
            loborder=np.array((5, 5))
            upborder=np.array((16, 14))

#        if np.array_equal(d, np.array([0., 0., 0.])):
#            loborder=np.array((10, 9))
#            upborder=np.array((22, 13))
#        elif np.array_equal(d, np.array([0., 0., 1.])):
#            loborder=np.array((12, 10))
#            upborder=np.array((20, 16))
#        elif np.array_equal(d, np.array([1., 1., 0.])):
#            print("not yet looked at")
#            loborder=np.array((12, 7))
#            upborder=np.array((16, 17))

    # for testing -> three intervalls on A40.24 TP0
    loborder = np.array((7,7))
    upborder = np.array((16, 16))

    return mpi, L, T, loborder, upborder

def analyse(lattice="A40.24", d=np.array([0., 0., 0.]), verbose=True):
    #######################################################
    ## definition of main variables
    nbsamples = 1500 # number of bootstrap samples
    tmin=1 # t0 for the GEVP calculation
    #d = np.array([0., 0., 1.]) # total momemtum of the system
    #lattice="A40.24" # lattice to analyse
    #######################################################
    # these variables are overwritten
    T=48
    L=24
    mpi=0.14463 # A40.24 from Carstens pipi I=2 analysis
    #######################################################
    ## define the fit function and start parameters
    #fitfunc = lambda p,t: p[0]*np.cosh((T/2.0-t)*p[1])
    #start_params = [0.005, -0.5]
    #fitfunc = lambda p,t: p[0]*np.exp(-p[1]*t)
    #start_params = [1.0, 0.5]
    #fitfunc = lambda p,t: np.exp(-p[0]*t)
    #start_params = [0.5]
    fitfunc = lambda p,t: 10e6 if p[1] < 0. else 0.5*p[0]*p[0]*(np.exp(-p[1]*t) + np.exp(-p[1]*(T-t)))
    start_params = [1, 0.5]
    massfunc = lambda p, t: p
    mass_sparams = [0.5]
    #######################################################
    ## setting variables
    d2 = np.dot(d, d)
    #path="".join(("/hiskp2/jost/data/rho_analyse/", lattice, "/"))
    path="".join(("/hiskp2/werner/analyse/" + lattice + "_mv%d" % d2 + "/Analysis/"))
    filelist = ["rho_corr_TP%d_00" % d2, "rho_corr_TP%d_01" % d2,\
                "rho_corr_TP%d_01" % d2, "rho_corr_TP%d_11" % d2]
    #filelist = ["rho_corr_TP%d_00" % d2]
    mpi, L, T, loborder, upborder = setup_lattice(lattice, d)
    print mpi, L, T
    ## print what is being calculated
    print("lattice %s, TP %d" % (lattice, d2))

    ## read in new data
    gevp_mat = read_new_data(nbsamples, path, filelist, tmin, lattice, d2)

    ## read in solution of GEVP
    #gevp_mat = ana.read_data("../raw_data/gevp_mat_rho_%s_TP%d.npy" % (lattice, d2))

    ## fit correlation function
    # 7-np.sqrt(d2) is empirical. For high momenta, there are no plateaus as long as
    # for the lower ones before running into exponential error growth.
    # use 7 for 20 and 24 TP0-2, 6 TP3-4, 9 for 32 TP0-2, 8 TP3-4
    res, chi2, pvals = fit_corr_ranges(gevp_mat, loborder, upborder, 
                                       7-np.sqrt(d2).astype(int), fitfunc, 
                                       start_params, tmin, lattice, d, True)
    #res, chi2, pvals = read_fit_corr(lattice, d)
    #return

    ## fit mass function NOT YET TESTED
    #massres, masschi2, masspvals = fit_mass(gevp_mat, lolist, uplist, massfunc,
    #    mass_sparams, tmin, lattice, d)
    #massres1, masschi21, masspvals1 = read_fit_mass(lattice, d)
    #print(np.array_equal(massres, massres1))

    ## calculate phaseshift
    ## TODO: Why does res[:][:,1] not have the right dimensions. Fix the fit 
    ## parameter to value for the energy
    meandata, statdata, systdata = calc_phaseshift(res, pvals, L, d, lattice, mpi)

    # print data
    print_results(meandata, statdata, systdata)
    filename="./data_mean_%s_TP%d.dat" % (lattice, d2)
    write_results(meandata, statdata, systdata, filename)

    return

def main():
    d0 = np.array([0., 0., 0.]) # total momentum of the system
    d1 = np.array([0., 0., 1.]) # total momentum of the system
    d2 = np.array([1., 1., 0.]) # total momentum of the system
    d3 = np.array([1., 1., 1.]) # total momentum of the system
    d4 = np.array([0., 0., 2.]) # total momentum of the system
    lattices=["A30.32", "A40.20", "A40.24", "A40.32", "A60.24",\
              "A80.24", "A100.24"]
    #A40
    #analyse(lattices[1], d0) 
    #analyse(lattices[1], d1)
    #analyse(lattices[1], d2)
    #analyse(lattices[1], d3)
    #analyse(lattices[1], d4)
    #analyse(lattices[2], d0)
    #analyse(lattices[2], d1)
    #analyse(lattices[2], d2)
    #analyse(lattices[2], d3)
    #analyse(lattices[2], d4)
    #analyse(lattices[3], d0)
    #analyse(lattices[3], d1)
    #analyse(lattices[3], d2)
    #analyse(lattices[3], d3)
    #analyse(lattices[3], d4)

    #A100
    analyse(lattices[6], d0)
    #analyse(lattices[6], d1)
    analyse(lattices[6], d2)
    #analyse(lattices[6], d3)
    #analyse(lattices[6], d4)

# make this script importable, according to the Google Python Style Guide
if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("\nKeyboard Interrupt, exiting...")
