#!/hadron/knippsch/Enthought/Canopy_64bit/User/bin/python
##!/usr/bin/python
################################################################################
#
# Author: Christian Jost (jost@hiskp.uni-bonn.de)
# Date:   Februar 2015
#
# Copyright (C) 2015 Christian Jost
# 
# This program is free software: you can redistribute it and/or modify it under 
# the terms of the GNU General Public License as published by the Free Software 
# Foundation, either version 3 of the License, or (at your option) any later 
# version.
# 
# This program is distributed in the hope that it will be useful, but WITHOUT 
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS 
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with tmLQCD. If not, see <http://www.gnu.org/licenses/>.
#
################################################################################
#
# Function: This is the start of the eta/eta' analysis program
#
# For informations on input parameters see the description of the function.
#
################################################################################

import sys
import numpy as np
import matplotlib
matplotlib.use('Agg') # has to be imported before the next lines
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages

import analysis as ana

def scat_length(dE, E, weight_dE, weight_E, L, pars=(1, 0)):
    """Finds root of the Energyshift function up to order L^{-5} only applicable
    in 0 momentum case, effective range not included!
    Only working for lists of lists.

    Args:
        dE: the energy shift of the system due to interaction
        E: the single particle energy
        weights_dE: weights of the energy shift
        weights_E: weights of the single particle energy
        L: The spatial lattice extent
        pars: which fit parameters to use, if None, skip the index
    Returns:
        a: roots of the function
        weights: the weight of a
    """
    ncorr_single = len(E)
    # check if dE has same length
    if len(dE) is not ncorr_single:
        print("error in calc_scat_length, data shapes incompatible")
        print(len(dE), len(E))
        os.sys.exit(-10)
    ncorr_ratio = [len(d) for d in dE]
    # check number of bootstrap samples and fit intervals for single particle
    for i in xrange(ncorr_single):
        for j in xrange(ncorr_ratio[i]):
            if E[i].shape[0] != dE[i][j].shape[0]:
                print("number of bootstrap samples is different in calc_scat_length")
                print(E[i].shape[0], dE[i][j].shape[0])
                os.sys.exit(-10)
            if E[i].shape[-1] != dE[i][j].shape[-1]:
                print("number of fit intervals is different in calc_scat_length")
                print(E[i].shape[-1], dE[i][j].shape[-1])
                os.sys.exit(-10)
    #print("scat length begin")
    ## number of correlation functions for the single particle energy
    #print(len(dE), len(E))
    ## number of correlation functions for the ratio
    #print(len(dE[0]))
    ## shape of the fit results
    #print(dE[0][0].shape, E[0].shape)
    # coefficients according to Luescher
    c=[-0.061367, -0.354156]
    # creating data array from empty array
    a = []
    weight = []
    for i in xrange(ncorr_single):
        a.append([])
        weight.append([])
        for j in xrange(ncorr_ratio[i]):
            a[i].append(np.zeros((E[i].shape[0], dE[i][j].shape[-2], E[i].shape[-1])))
            weight[i].append(np.zeros((dE[i][j].shape[-2], E[i].shape[-1])))
    # loop over the correlation functions
    for _r in xrange(ncorr_single): # single particle
        for _s in xrange(ncorr_ratio[_r]): # ratio
            # calculate prefactor
            # TODO(CJ): can the shape of E[i] change?
            if pars[1] == None:
                pre = -12./(E[_r]*float(L*L))
                pre2 = 4.*np.pi/(E[_r]*float(L*L))
            else:
                pre = -12./(E[_r][:,pars[1]]*float(L*L))
                pre2 = 4.*np.pi/(E[_r][:,pars[1]]*float(L*L))
            # loop over fitranges
            for _f in xrange(E[_r].shape[-1]): # single particle
                for _g in xrange(dE[_r][_s].shape[-2]): # ratio
                    # loop over bootstrap samples
                    for _b in xrange(E[_r].shape[0]):
                        if pars[0] == None:
                            p = np.asarray((pre[_b,_f]*c[1], pre[_b,_f]*c[0],
                                pre[_b,_f], pre2[_b,_f] - 1.*dE[_r][_s][_b,_g,_f]))
                        else:
                            p = np.asarray((pre[_b,_f]*c[1], pre[_b,_f]*c[0],
                                pre[_b,_f], pre2[_b,_f] - 1.*dE[_r][_s][_b,pars[0],_g,_f]))
                        # calculate roots
                        root = np.roots(p)
                        # sort according to absolute value of the imaginary part
                        ind_root = np.argsort(np.fabs(root.imag))
                        if(root[ind_root][0].imag) > 1e-6:
                            print("imaginary part of root > 1e-6 for c1 %d, c2 %d, f1 %d, f2 %d, b %d" % (_r, _s, _f, _g, _b))
                        # the first entry of the sorted array is the one we want
                        a[_r][_s][_b, _g, _f] = root[ind_root][0].real
                        weight[_r][_s][_g, _f] = weight_dE[_r][_s][_g,_f] * weight_E[_r][_f]
    return a, weight

def read_data(path, pilist, pipilist, datafolder, nsamples, lattice, d,
              readnew=True, verbose=False):
    d2 = np.dot(d,d)
    suffix="%s_TP%d.npy" % (lattice, d2)
    if not verbose:
        print("reading data")
    if readnew:
        if verbose:
            print("reading files:")
            for f in pilist:
                print(f)
            for f in pipilist:
                print(f)
        pipi_data = ana.create_corr_matrix(nsamples, path, pipilist)
        corr = ana.read_data_ascii("".join((path, pilist[0])))
        pi_data = ana.sym_and_boot(corr, nsamples)
        ana.write_data(pipi_data, "%s/pipi_data_%s" % (datafolder, suffix))
        ana.write_data(pi_data, "%s/pi_data_%s" % (datafolder, suffix))
    else:
        if verbose:
            print("reading numpy data")
        pipi_data = ana.read_data("%s/pipi_data_%s" % (datafolder, suffix))
        pi_data = ana.read_data("%s/pi_data_%s" % (datafolder, suffix))
    if verbose:
        print("data shapes")
        print(pi_data.shape)
        print(pipi_data.shape)
    return pi_data, pipi_data

def fit_single_pion(ensemble, pi_data, pars, pionfit, label, plotfolder,
    datafolder, newfit=True, verbose=True):
    """Fit the correlation function for the single pion.

    Args:
        ensemble: the ensemble to fit
        pi_data: the correlation function
        pars: the start parameters for the fit
        pionfit: fit function for the correlator
        label: label for the plots
        plotfolder: path to save the plots
        datafolder: path to save the fit results
        newfit: do the fit, if false read data from disk
        verbose: amount of information written on screen

    Returns:
        pi: the resulting parameters from the fit
        chi2: the chi^2 of each fit
        pvals: the p-values of each fit
        fitranges: the used fitranges
    """
    d = ensemble.get_data("d")
    lattice = ensemble.name
    d2 = np.dot(d, d)
    lo = ensemble.get_data("lo_pion")
    up = ensemble.get_data("up_pion")
    fmin = ensemble.get_data("fmin")
    fname = "%s/fit_results_%s_TP%d.npz" % (datafolder, lattice, d2)
    if not verbose:
        print("fitting single pion")
    if newfit:
        pion_fit = ana.FitResults(ensemble, "single pion")
        if verbose:
            pion_fit.toggle_verbose()
        if verbose:
            print("new fit")
            print(pi_data.shape)
        pion_fit.add_fitrange(ana.set_fit_interval(pi_data, lo, up, fmin))
        pion_fit.use_old_data(fname)
        pion_fit.fit(pi_data, pionfit, pars)
        pion_fit.save(fname)
        pion_fit.plot(label, plotfolder, "pion_mass")
        return pion_fit.get_results()
    else:
        if verbose:
            ("reading fit data")
        pionranges, pi, chi2, pvals = ana.read_fitresults(fname)
        ana.genplot(pi_data, pi, pvals, pionranges, pionfit, tmin, lattice, d,
                    label, plotfolder, "pion_mass", verbose=verbose)
        return pi, chi2, pvals, pionranges
 

def calc_gevp(data, s, tmin, d2, datafolder, lattice, solvenew=True, 
              verbose=False):
    """Shift the correlation function matrix and solve the gevp.

    Args:
        data: correlation function matrix
        s: number of timeslices to shift
        tmin: t0 for the GEVP solver
        d2: total momentum squared
        datafolder: folder where to store numpy data
        lattice: the name of the lattice
        solvenew: If true recalculate, if false read from disk
        verbose: amount of information written to screen

    Returns:
        gevp: solution of the GEVP
        mgevp: mean of the solution of the GEVP
        dgevp: std of the solution of the GEVP
    """
    fname = "%s/pipi_corr_mat_%s_TP%d_s%d_tmin%d.npy" % (datafolder, lattice, d2, s, tmin)
    if solvenew:
        if verbose:
            print("shift %d" % s)
        data_shift = ana.shift_corr_matrix(data, s)

        if verbose:
            print("shifted data")
            print(data_shift.shape)

        ## GEVP
        gevp = ana.calculate_gevp(data_shift, tmin)
        ana.write_data(gevp, fname)
    else:
        if verbose:
            print("read shifted data")
        gevp = ana.read_data(fname)
    mgevp, dgevp = ana.calc_error(gevp)
    
    if verbose:
        print("gevp shapes")
        print(gevp.shape)
        print(mgevp.shape)
        print(dgevp.shape)

    return gevp, mgevp, dgevp

def analyse(ensemble, datafolder, plotfolder):
    """pi-pi scattering analysis for I=2.

    Args:
        ensemble: the ensemble to work on
        datafolder: where to store raw data
        plotfolder: where to store the plots
    """
    ## define main variables
    readnewdata=False
    fitsinglepion=True
    calculategevp=False
    fitratio=False
    verbose=False
    nsamples = 1500 # number of bootstrap samples
    tmin = 1 # for the GEVP
    ensemble.add_data("tmin", tmin)

    ## other variables
    # total momentum
    d = ensemble.get_data("d")
    d2 = np.dot(d, d)
    L = ensemble.L
    T = ensemble.T
    T2 = ensemble.T2
    gmax = ensemble.get_data("gmax")
    lattice = ensemble.name
    path = ensemble.get_data("path")
    slist = ensemble.get_data("s")
    # file list
    pipilist = ["pipi_pipi_A1_corr_TP%d_%d%d" % (d2, x, y) for x in range(gmax)
                for y in range(gmax)]
    pilist = ["pi_corr_p%d.dat" % d2 ]
    # fit functions
    massfit = lambda p,t : p
    pionfit = lambda p, t: 0.5*p[0]*p[0]*(np.exp(-p[1]*t)+np.exp(-p[1]*(T2-t)))
    ratiofit = lambda p, t, e : p[0]*(np.cosh(p[1]*(t-T-1))+\
                                np.sinh(p[1]*(t-T2-1))/(np.tanh(2*e*(t-T2-1))))
    # label for the plots
    label_pion = ["single pion", "time", "am$_{\pi}$(t)", "data", ""]
    label_ratio = ["ratio", "time", "R(t)", "data", ""]
    # lower and upper fit ranges for the different correlators
    lo_pion = [8]
    up_pion = [T2]
    if (L == 24) or (L==20):
        lo_ratio = [8, 10, 4, 4, 4]
        up_ratio = [16, 18, 7, 7, 7]
        # minimal number of points in each fit
        fmin = 4
    elif L == 32:
        lo_ratio = [10, 15, 4, 4, 4]
        up_ratio = [20, 25, 7, 7, 7]
        # minimal number of points in each fit
        fmin = 6
    elif L == 48:
        lo_ratio = [21, 26, 4, 4, 4]
        up_ratio = [32, 37, 7, 7, 7]
        # minimal number of points in each fit
        fmin = 7
    else:
        print("no fit ranges given for L = %d" % L)
        sys.exit(-1)
    if lattice == "A40.24":
        lo_ratio = [8, 10, 4, 4, 4]
        up_ratio = [20, 20, 7, 7, 7]
    # minimal number of points in each fit
    fmin = 4
    # initial parameters for the fits
    par_pion = [0.2]
    par_ratio = [2., 0.06]
    ensemble.add_data("lo_pion", lo_pion)
    ensemble.add_data("up_pion", up_pion)
    ensemble.add_data("fmin", fmin)

    ## read in data
    pi_data, pipi_data = read_data(path, pilist, pipilist, datafolder,
                                   nsamples, lattice, d, readnew=readnewdata)

    ## calculate effective mass of the pion
    pimass, pimmass, pidmass = ana.compute_mass(pi_data)
    ## fit single pion effective mass function
    pi, pichi2, pipvals, pionranges = fit_single_pion(ensemble, pimass,
        par_pion, massfit, label_pion, plotfolder, datafolder,
        newfit=fitsinglepion)
    # calculate statistic and systematic error of the pion
    plotname="".join(("pion_", lattice))
    mpi, dmpi_stat, dmpi_syst, weights_mpi = ana.sys_error(pi, pipvals, d, 
                                                 plotname, path=plotfolder)
    if verbose:
        print("single pion")
        print(len(weights_mpi))
        for p in weights_mpi:
            print(d.shape)
    print("mpi with errors")
    for p, dp, ddp in zip(mpi, dmpi_stat, dmpi_syst):
        print("%.5f +- %.5f -%.5f +%.5f" % (p, dp, ddp[0], ddp[1]))

    return

    gevp, mgevp, dgevp = [], [], []
    mass_gevp, mmass_gevp, dmass_gevp = [], [], []
    for s in slist:
        print("shift %d" % s)
        ## GEVP
        tgevp, tmgevp, tdgevp=calc_gevp(pipi_data, s, tmin, d2, datafolder, lattice,
                                     solvenew=calculategevp)
        gevp.append(tgevp)
        mgevp.append(tmgevp)
        dgevp.append(tdgevp)

        tmass_gevp, tmmass_gevp, tdmass_gevp = ana.compute_mass(tgevp, usecosh=True)
        mass_gevp.append(tmass_gevp)
        mmass_gevp.append(tmmass_gevp)
        dmass_gevp.append(tdmass_gevp)

        #tlist = np.linspace(0., float(tmass_gevp.shape[1]), float(tmass_gevp.shape[1]), endpoint=False)
        #for a in range(tgevp.shape[2]):
        #  ana.plot_data(tlist, tmass_gevp[:,:,a], tdmass_gevp[:,a], gevpplot)

        ## build ratio to determine dE
        #print("calculating ratio")
        ratio, mratio, dratio=ana.simple_ratio_subtract(tgevp, pi_data, pi_data)

        ## TODO(CJ): ONLY USE 2 LOWEST CORRELATORS ATM
        ratio = ratio[:,:,:2]
        mratio = mratio[:,:2]
        dratio = dratio[:,:2]

        # fit ratio
        print("fitting ratio")
        fname = "%s/fit_ratio_%s_TP%d_s%d.npz" % (datafolder, lattice, d2, s)
        if fitratio:
            ratioranges = ana.set_fit_interval(ratio, lo_ratio, up_ratio, fmin)
            rres, rchi2, rpvals = ana.genfit_comb(ratio, ratioranges, pionranges,
                ratiofit, par_ratio, pi, tmin, lattice, label_ratio, plotfolder,
                "ratio_s%d" % s, verbose=False)
            ana.write_fitresults(fname, ratioranges, rres, rchi2, rpvals)
        else:
            ratioranges, rres, rchi2, rpvals = ana.read_fitresults(fname)
        #if verbose:
        #    print("rres")
        #    print(len(rres))
        #    for p in rres:
        #        print(len(p))
        #        for q in p:
        #            print(q.shape)
        #    print("rpvals")
        #    print(len(rpvals))
        #    for p in rpvals:
        #        print(len(p))
        #        for q in p:
        #            print(q.shape)

        # calculate statistic and systematic error for delta E
        plotname = "ratio_s%d_%s" % (s, lattice)
        dE, ddE_stat, ddE_syst, weights_dE = ana.sys_error(rres, rpvals, d, 
            plotname, par=1, path=plotfolder, absolute=True)

        #if verbose:
        #    print("weights_dE")
        #    print(len(weights_dE))
        #    for p in weights_dE:
        #        print(len(p))
        #        for q in p:
        #            print(q.shape)
        #    print(len(dE))
        #    for p in dE:
        #        print(len(p))
        #        for q in p:
        #            print(q)
        print("dE with errors")
        for p, dp, ddp in zip(dE, ddE_stat, ddE_syst):
            for q, dq, ddq in zip(p, dp, ddp):
                print("%.4f +- %.4f -%.4f +%.4f" % (q, dq, ddq[0], ddq[1]))

        ## calculate scattering length
        print("calculating scattering length")
        anew = False
        mom=True
        fname = "%s/test_scat_len_%s_TP%d_s%d.npz" % (datafolder, lattice, d2, s)
        if anew:
            if mom == False:
                a, weights_a = ana.calc_scat_length(rres, pi, weights_dE, weights_mpi, L)
            else:
                a, weights_a = scat_length(rres, pi, weights_dE, weights_mpi, L)
            # since a is a list of lists of arrays, hack the fit results
            # routines to save
            ana.write_fitresults(fname, np.zeros((10,)), a, weights_a, a)
        else:
            # since a is a list of lists of arrays, hack the fit results
            # routines to read
            _u, _a, weights_a, a = ana.read_fitresults(fname)
        #print("a")
        #print(len(a))
        #for p in a:
        #    print(len(p))
        #    for q in p:
        #        print(q.shape)
        #print("weights_a")
        #print(len(weights_a))
        #for p in weights_a:
        #    print(len(p))
        #    for q in p:
        #        print(q.shape)

        # statistical error for scattering length
        a_pipi, da_stat, da_syst = ana.sys_error_der(a, weights_a, d, lattice, path=plotfolder)
        #print("a_pipi")
        #print(len(a_pipi))
        #for p in a_pipi:
        #    print(len(p))
        #    for q in p:
        #        print(q.shape)
        print("a_pipi with errors")
        for p, dp, ddp in zip(a_pipi, da_stat, da_syst):
            for q, dq, ddq in zip(p, dp, ddp):
                print(q, dq, ddq)

        # calculate mpi * a
        #ampinew = True
        #fname = "%s/ampi_%s_TP%d_s%d.npz" % (datafolder, lattice, d2, s)
        #if ampinew:
        #    ampi, weights_ampi = ana.multiply(a, pi, weights_a, weights_mpi, pars=(None, 0))
        #    ana.write_fitresults(fname, np.zeros((10,)), ampi, weights_ampi, ampi)
        #else:
        #    _u, _ampi, weights_ampi, ampi = ana.read_fitresults(fname)

        ## statistical and systematic error for a*mpi
        #am_pipi, dam_stat, dam_syst = ana.sys_error_der(ampi, weights_ampi, d, lattice, path=plotfolder)
        #print("a_pipi * m_pi")
        #print(len(ampi))
        #for p in ampi:
        #    print(len(p))
        #    for q in p:
        #        print(q.shape)
        #print("a_pipi * m_pi with errors")
        #for p, dp, ddp in zip(am_pipi, dam_stat, dam_syst):
        #    for q, dq, ddq in zip(p, dp, ddp):
        #        print(q, dq, ddq)
    gevpplot = PdfPages("%s/gevp_check_plots_%s_TP%d_tmin%d.pdf" % (plotfolder, lattice, d2, tmin))
    for pc in xrange(mass_gevp[0].shape[-1]):
        p = []
        test_mpi = np.sqrt(mpi[0]**2 + (2. * np.pi * float(pc) / float(L))**2 )
        for i in xrange(len(mass_gevp)):
            da = mass_gevp[i][:,:,pc]
            dda = dmass_gevp[i][:,pc]
            tlist = np.linspace(0., float(da.shape[1]), float(da.shape[1]), endpoint=False)
            p.append(plt.errorbar(tlist, da[0], dda, fmt='x', label="shift %d" % i))
        x1 = np.linspace(tlist[0], tlist[-1], 1000)
        y1 = np.ones_like(x1)*2.*test_mpi
        p.append(plt.plot(x1, y1, "r", label="2m$_{\pi}$ + p$^2$=%d" % pc))
        plt.grid(True)
        plt.xlabel("t")
        plt.ylabel("C(t)")
        plt.title("pc %d, shift vs non-shift" % pc)
        plt.legend()
        gevpplot.savefig()
        plt.clf()
    gevpplot.close()
    return

def main():
    d0 = np.array([0., 0., 0.]) # total momentum of the system
    lattices=["A30.32", "A40.20", "A40.24", "A40.32", "A60.24",
              "A80.24", "A100.24", "B25.32", "B35.32", "B35.48",
              "B55.32", "B85.24", "D15.48", "D30.48", "D45.32"]
    if len(sys.argv) < 2:
        ens = 2
    elif int(sys.argv[1]) >= len(lattices):
        print("ensemble not known, the following are known.")
        print(lattices)
        sys.exit(-11)
    else:
        ens = int(sys.argv[1])
        if lattices[ens] == "D30.48":
            print("D30.48 not calculated yet")
            sys.exit(-11)
    if len(sys.argv) < 3:
        s = 0
    elif int(sys.argv[2]) < 4:
        s = int(sys.argv[2])
    else:
        print("shift of %d does not make sense" % (sys.argv[2]))
        sys.exit(-11)

    path = ["/hiskp2/correlators/A30.32_L32_T64_beta190_mul0030_musig150_mudel190_kappa1632720/ev220/liuming/",
            "/hiskp2/correlators/A40.20_L20_T48_beta190_mul0040_musig150_mudel190_kappa1632700/ev066/liuming/",
            "/hiskp2/correlators/A40.24_L24_T48_beta190_mul0040_musig150_mudel190_kappa1632700/ev120/liuming/",
            "/hiskp2/correlators/A40.32_L32_T64_beta190_mul0040_musig150_mudel190_kappa1632700/liuming/",
            "/hiskp2/correlators/A60.24_L24_T48_beta190_mul0060_musig150_mudel190_kappa1632650/ev120/liuming/",
            "/hiskp2/correlators/A80.24_L24_T48_beta190_mul0080_musig150_mudel190_kappa1632600/ev120/liuming/",
            "/hiskp2/correlators/A100.24_L24_T48_beta190_mul0100_musig150_mudel190_kappa1632550/ev120/liuming/",
            "/hiskp2/correlators/B25.32/christopher/",
            "/hiskp2/correlators/B35.32/liuming/",
            "/hiskp2/correlators/B35.48/liuming/",
            "/hiskp2/correlators/B55.32_L32_T64_beta195_mul0055_musig135_mudel170_kappa1612360/ev220/liuming/",
            "/hiskp2/correlators/B85.24/liuming/",
            "/hiskp2/correlators/D15.48/liuming/",
            "", # D30.48 not calculated yet
            "/hiskp2/correlators/D45.32_L32_T64_beta210_mul0045_musig0937_mudel1077_kappa1563150/ev220/liuming/"]
    gmax = [3, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]
    datafolder = "./raw_data/"
    plotfolder = "./plots/"
    ensembles = []
    for i, lat in enumerate(lattices):
        L = int(lat[-2:])
        T = 2*L
        if L == 20:
            T=48
        ensembles.append(ana.LatticeEnsemble(lat, L, T))
        ensembles[-1].add_data("path", path[i])
        ensembles[-1].add_data("gmax", gmax[i])
        ensembles[-1].add_data("s", [0,1])
        ensembles[-1].add_data("d", d0)
    #print(ensembles)
    #for e in ensembles:
    #    print(e)
    #ensembles[0].get_data("x")

    print("calculating %s" % (lattices[ens]))
    analyse(ensembles[ens], datafolder, plotfolder)
    return

# make this script importable, according to the Google Python Style Guide
if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        pass
