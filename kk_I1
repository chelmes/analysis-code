#!/hadron/knippsch/Enthought/Canopy_64bit/User/bin/python
################################################################################
#
# Author: Christopher Helmes (helmes@hiskp.uni-bonn.de)
# Date:   Februar 2015
#
# Copyright (C) 2015 Christopher Helmes
# 
# This program is free software: you can redistribute it and/or modify it under 
# the terms of the GNU General Public License as published by the Free Software 
# Foundation, either version 3 of the License, or (at your option) any later 
# version.
# 
# This program is distributed in the hope that it will be useful, but WITHOUT 
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS 
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with tmLQCD. If not, see <http://www.gnu.org/licenses/>.
#
################################################################################
#
# Function: Pi-Pi-scattering analysis in the center of mass frame 
#
# For informations on input parameters see the description of the function.
#
################################################################################

# system imports
import os.path as osp
from scipy import stats
import numpy as np
from numpy.polynomial import polynomial as P
import matplotlib
matplotlib.use('Agg') # has to be imported before the next lines
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages

# Christian's packages
import analysis as ana
def main():
    # number of bootstrap samples
    nbsamples = 1500
    # temporal lattice extent
    tmin = 1
    T = 64
    L = 32
    # Strange quark masses and unitary kaon mass
    #mk_unit = 0.26695
    #dmk_unit = 0.00052
    #A-ensemble strange quark masses, only needed for names
    #amu_s = ['186'] 
    #B-ensemble strange quark masses
    #amu_s = [0.016, 0.01861, 0.021]
    p_zero = np.asarray([0,0,0])
    amu_s = ['225','2464']
    ensemblelist = ['A30.32/']
    #ensemblelist = ['A40.24/','A60.24/','A80.24/','A100.24/']
    #ensemblelist = ['3_rnd_vec/','4_rnd_vec/','5_rnd_vec/']
    filelist = ['k_charged_p0.dat','kk_charged_A1_TP0_00.dat']
    #filelist = ['C2.dat','kpi_4.dat']
    #pathroot = "/hiskp2/helmes/k-k-scattering/tests/5_rnd_vec/"
    pathroot = "/hiskp2/helmes/analysis/scattering/k_charged/"
    #pathroot ="/hiskp2/helmes/k-k-scattering/tests/A40.24/"

    for ens in ensemblelist:

        # Constructing all needed paths
        datapath = pathroot+"data/"+ens
        cachepath = pathroot+"cache/"+ens
        plotpath = pathroot+"plots/"+ens
        save_res=open(datapath+"res.dat","w")
        save_res.write("amu_s\tm_k d_stat(m_k) +d_sys(m_k) -d_sys(m_k)\t delE d_stat(delE) +d_sys(delE) -d_sys(delE)\ta_kk d_stat(a_kk)\tm_k*a_kk d_stat(m_k*a_kk)\n") 
        #print datapath
        #Numpy array to hold all data at end
        m_k_dat = [] #np.zeros((len(amu_s), nbsamples))
        a_k_dat = [] #np.zeros((len(amu_s), nbsamples))
        for mu_s in amu_s:
            # need two cachepaths
            #name_cache_k = cachepath
            #name_cache_kk = cachepath
            name_cache_k = cachepath+ens[:-1]+"_"+mu_s+"_"+filelist[0]
            name_cache_kk = cachepath+ens[:-1]+"_"+mu_s+"_"+filelist[1]
            print name_cache_k
            #set up paths for data read in and result storage
            path = datapath
            #path = datapath
            print path
            tmp_out = plotpath
            #tmp_out = pathroot+"plots/"+ens+"amu_s_"+str(amu_s[s])[3:]
            #tmp_out = pathroot+ens+"plots/"
            # start with usual analysis (thermal states contamination expected)
            fitfunc = lambda p,t: 10e6 if p[1] < 0.0 else 0.5*p[0]*p[0]*(np.exp(-p[1]*t) + np.exp(-p[1]*(T-t)))
            par_mass = [1.]
            par_ratio = [1.,1.]
            massfunc = lambda p, t: p
            
            T2=int(T/2)+1
            tlist_corr = np.linspace(0., float(T2-1), float(T2-1), endpoint=False)
            tlist_ratio = np.linspace(0.5, float(T2-0.5), float(T2-1), endpoint=False)


            #-------------------- data input ----------------------------

            # Check if data is already cached
            test_k = name_cache_k+".npy"
            test_kk = name_cache_kk+".npy"
            if osp.isfile(test_k) and osp.isfile(test_kk):
                #print("reusing samples %s and\n%s" % (test_k, test_kk))
                bsamples_k = ana.read_data(test_k)
                bsamples_kk = ana.read_data(test_kk)
            else:
            # else read data anew
                print("Starting from scratch")
                in_path ="/".join((datapath,'amu_s_'+ mu_s)) 
                print("Reading samples from %s" % in_path)
                corrs_k = ana.read_data_ascii(in_path + "/" + filelist[0])
                corrs_kk = ana.read_data_ascii(in_path + "/" +filelist[1])
                nbcfg = corrs_k.shape[0]
                # Create symmetrized bootstrap samples of 2pt and 4pt Corr-function
                bsamples_k = ana.sym_and_boot(corrs_k, nbsamples)
                bsamples_kk = ana.sym_and_boot(corrs_kk, nbsamples)
                # Cache Bootstrapsamples using tested Cachename
                ana.write_data(bsamples_k, name_cache_k)
                ana.write_data(bsamples_kk, name_cache_kk)
                print("Samples cached in %s" % cachepath)

            # Check mean correlators
            corr_k_data, d_k_data = ana.calc_error(bsamples_k)
            corr_kk_data, d_kk_data = ana.calc_error(bsamples_kk)



            #------------------- m_k from bsamples_k --------------------------

            label = ["Kaon m_eff", "time", "C(t)", "data", ""]
            up=T/2-1
            # due to small variance changes can fit single correlators to the end
            mass, mmass, dmass = ana.compute_mass(bsamples_k, True)
            # ana.scan_fit_range(massfunc, tlist_corr,mass, par_mass)
            # TODO: set two points more than wanted for upper limit
            ranges = ana.set_fit_interval(mass, [9], [33], 10)
            # For mass use one parameter fit
            # res has shape (nb_samples, nb_pars, ncorr, nb_fitranges)
            print str(ens[:-1])
            prefix = "_"+str(ens[:-1])+mu_s

            # Check and conditionally read cache of fit
            genfit_mass_cache = name_cache_k+"genfit_mass"
            if osp.isfile(genfit_mass_cache+".npz"):
                ranges, res, chi2, pval = ana.read_fitresults(genfit_mass_cache+".npz")
            else:
                res, chi2, pval = ana.genfit(mass,ranges,massfunc,
                    par_mass,1,prefix,np.asarray([0,0,0]),label,cachepath,"mass",False)
                print len(ranges)
                
                # Save fit results
                print("saving Mass fits to %s" %genfit_mass_cache)
                ana.write_fitresults(genfit_mass_cache, ranges, res, chi2, pval)
          
            np.append(m_k_dat,res)
            prefix = ens[:-1]+"_mass_"+mu_s 
            m_k_w, dm_stat, dm_sys, _weights_m_k = ana.sys_error(res,pval,
                p_zero,prefix,
                path=tmp_out,boot=True)
            # save weighted kaon mass samples
            m_k_path = datapath + "m_k_" + mu_s + ".npy" 
            ana.write_data(m_k_w, m_k_path)
            print("m_k +/- d_stat(m_k) + d_sys(m_k) -d_sys(m_k)\n%f +/- %f +%f-%f\n" 
                %(m_k_w[0][0], dm_stat[0], dm_sys[0][0], dm_sys[0][1]))
            #print("weights_m_k shape is:%d" % weights_m_k.shape)


            #----- Calc 4 pt mean correlator and effective mass ---------------

            label = ["KK 4pt func", "time", "C4(t)", "data", ""]
            pfit = PdfPages("%s%sC4_%s_plot.pdf" % (tmp_out,"m_eff_",mu_s)) 
            ana.plot_data_with_fit(tlist_corr, corr_kk_data, d_kk_data, massfunc, [0], [1,T2-2], label, pfit, logscale=True )
            label[2] = "m_eff_4pt(t)"
            m_eff_C4, mm_eff_C4, dm_eff_C4 = ana.compute_mass(bsamples_kk, True)
            ana.plot_data_with_fit(tlist_corr, mm_eff_C4, dm_eff_C4, massfunc,
                [0], [1,T2-2], label, pfit, False, False)
            pfit.close()


            #-------------- Ratio of C_kk and C_k^2 ---------------------------

            R_boot, R_mean, R_stdev, = ana.simple_ratio_subtract(bsamples_kk, bsamples_k, bsamples_k)
            label = ["Ratio K-K", "time", "R(t)", "data", ""]
            # plot mean ratio
            pfit = PdfPages("./"+ens[:-1]+"_orig_Ratio_%s.pdf" % mu_s)
            ana.plot_data(tlist_ratio, R_boot[0], R_stdev, pfit, label,[1,T2-2])
            pfit.close()
            # define the ratiofunction, Using fitted energies seems to make more
            # sense
            ratio = lambda p, t, e : p[0]*(np.cosh(p[1]*(t-T/2))+np.sinh(p[1]*(t-T/2))/(np.tanh(2*e*(t-T/2))))
            # Check and conditionally read cache of fit
            genfit_ratio_cache = name_cache_k+"genfit_ratio"
            if osp.isfile(genfit_ratio_cache+".npz"):
              ranges1, res_R, chi2_R, pvals_R = ana.read_fitresults(genfit_ratio_cache+".npz")
            else:
              # define fit ranges
                 #res_R has shape (nb_samples, nb_pars, n_corr, nb_ranges1 * nb_ranges2)
                ranges1 = ana.set_fit_interval(R_boot,[17],[T2-1],14)
                res_R, chi2_R, pvals_R = ana.genfit_comb(R_boot,ranges1,ranges,
                    ratio,par_ratio,res,
                    1,ens[:-1],label,tmp_out,
                    "ratio", verbose=True)
                # Save fit results
                ana.write_fitresults(genfit_ratio_cache, ranges1, res_R, chi2_R, pvals_R)

            prefix = ens[:-1]+"ratio_"+mu_s
            del_E_w, ddel_E_stat, ddel_E_sys , weights_del_E = ana.sys_error(res_R,
                pvals_R, p_zero,
                prefix,par=1,
                path=tmp_out,
                boot = True)
            print weights_del_E
            print("delE +/- d_stat(del_E) + d_sys(del_E) -d_sys(del_E)\n%f +/- %f +%f -%f\n" 
                %(del_E_w[0][0][0], ddel_E_stat[0][0], ddel_E_sys[0][0][0], ddel_E_sys[0][0][1]))


            #---------------------- Scattering length a_kk --------------------

            # calculate Scattering length
            a_kk = ana.calc_scat_length_bare(del_E_w, m_k_w, L)
            print a_kk[0][0][0]
            mean_a_kk, std_a_kk = ana.calc_error(a_kk[0][0])



            #------------------------- m_k*a_kk -------------------------------

            # Using bootstrapped median of a_kk and m_k
            ma_k = np.multiply(a_kk, m_k_w)
            scat_length_path = datapath + "mk_a0_" + mu_s + ".npy" 
            ana.write_data(ma_k, scat_length_path)
            print ma_k.shape
            mean_mak, std_mak = ana.calc_error(ma_k[0][0])
            print "M_K a_KK = %f +/- %f" % (  mean_mak, std_mak)


            #save_res.write("%f\t%f %f +%f -%f\t%f +/- %f +%f -%f\t%f +/- %f\t%f +/- %f\n" 
            #  %(amu_s[s], m_k_w[0], dm_stat[0], dm_sys[0][0], dm_sys[0][1], 
            #  del_E_w[0][0], ddel_E_stat[0][0], ddel_E_sys[0][0][0],ddel_E_sys[0][0][1],
            #  mean_a_kk.astype(float), std_a_kk.astype(float),
            #  mean_mak.astype(float), std_mak.astype(float)))

        
        save_res.close()

# make this script importable, according to the Google Python Style Guide
if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("Keyboard Interrupt")
