#!/usr/bin/python
################################################################################
#
# Author: Christopher Helmes (helmes@hiskp.uni-bonn.de)
# Date:   Februar 2015
#
# Copyright (C) 2015 Christopher Helmes
# 
# This program is free software: you can redistribute it and/or modify it under 
# the terms of the GNU General Public License as published by the Free Software 
# Foundation, either version 3 of the License, or (at your option) any later 
# version.
# 
# This program is distributed in the hope that it will be useful, but WITHOUT 
# ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS 
# FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License
# along with tmLQCD. If not, see <http://www.gnu.org/licenses/>.
#
################################################################################
#
# Function: Pi-Pi-scattering analysis in the center of mass frame 
#
# For informations on input parameters see the description of the function.
#
################################################################################

# system imports
import os.path as osp
from scipy import stats
import numpy as np
from numpy.polynomial import polynomial as P
import matplotlib
matplotlib.use('QT4Agg') # has to be imported before the next lines
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages

# Christian's packages
import analysis as ana
def main():
    # number of bootstrap samples
    nbsamples = 1500
    # temporal lattice extent
    tmin = 1
    T = 48
    L = 24
    # Strange quark masses and unitary kaon mass
    mk_unit = 0.26695
    dmk_unit = 0.00052
    amu_s = [0.0185,0.0225,0.02464]
    #amu_s = [1]
    #ensemblelist = ['A40.24/','A60.24/','A80.24/','A100.24/']
    ensemblelist = ['A100.24/']
    filelist = ['k_corr_p0.dat','kk_A1_TP0_00.dat']
    #filelist = ['C2.dat','kpi_4.dat']
    pathroot ="/hiskp2/helmes/k-k-scattering/"
    for ens in ensemblelist:
        datapath = pathroot+"data/"+ens
        cachepath = pathroot+"data/cache/"
        print datapath
        #Numpy array to hold all data at end
        m_k_dat = [] #np.zeros((len(amu_s), nbsamples))
        a_k_dat = [] #np.zeros((len(amu_s), nbsamples))
        m_k_unit =[] # np.zeros(nbsamples)

        for s in range(0,len(amu_s)):
            # need two cachepaths
            name_cache_k = cachepath+ens[:-1]+"_"+str(amu_s[s])[3:]+"_"+filelist[0]
            name_cache_kk = cachepath+ens[:-1]+"_"+str(amu_s[s])[3:]+"_"+filelist[1]
            #set up paths for data read in and result storage
            path = datapath+"amu_s_"+str(amu_s[s])[3:]+"/"
            #path = datapath
            #tmp_out = pathroot+"plots/"+ens+"amu_s_"+str(amu_s[s])[3:]
            tmp_out = pathroot+"plots/"
            pfit = PdfPages("%s%sk_plot.pdf" % (tmp_out,"_corr_")) 
            prat = PdfPages("%s%skk_plot.pdf" % (tmp_out,"_ratio_")) 
            # start with usual analysis (thermal states contamination expected)
            fitfunc = lambda p,t: 10e6 if p[1] < 0.0 else 0.5*p[0]*p[0]*(np.exp(-p[1]*t) + np.exp(-p[1]*(T-t)))
            par_mass = [1.]
            par_ratio = [2.,0.06,0.3]
            massfunc = lambda p, t: p
            
            T2=int(T/2)+1
            tlist_corr = np.linspace(0., float(T2), float(T2), endpoint=False)
            tlist_ratio = np.linspace(0.5, float(T2-0.5), float(T2-1), endpoint=False)


            #-------------------- data input ----------------------------

            # Check if data is already cached
            test_k = name_cache_k+".npy"
            test_kk = name_cache_kk+".npy"
            if osp.isfile(test_k) and osp.isfile(test_kk):
                print("reusing samples %s and\n%s" % (test_k, test_kk))
                bsamples_k = ana.read_data(test_k)
                bsamples_kk = ana.read_data(test_kk)
            else:
            # else read data anew
                print("Starting from scratch")
                corrs_k = ana.read_data_ascii("".join((path, filelist[0])))
                corrs_kk = ana.read_data_ascii("".join((path, filelist[1])))
                nbcfg = corrs_k.shape[0]
                # Create symmetrized bootstrap samples of 2pt and 4pt Corr-function
                bsamples_k = ana.sym_and_boot(corrs_k, nbsamples)
                bsamples_kk = ana.sym_and_boot(corrs_kk, nbsamples)
                # Cache Bootstrapsamples using tested Cachename
                ana.write_data(bsamples_k, name_cache_k)
                ana.write_data(bsamples_kk, name_cache_kk)
                print("Samples cached in %s" % cachepath)

            # Check mean correlators
            corr_k_data, d_k_data = ana.calc_error(bsamples_k)
            corr_kk_data, d_kk_data = ana.calc_error(bsamples_kk)


            #------------------- m_k from bsamples_k --------------------------

            label = ["single Kaon, "+ens, "time", "C(t)", "data", ""]
            up=23

            # due to small variance changes can fit single correlators to the end
            mass, mmass, dmass = ana.compute_mass(bsamples_k, True)
            # ana.scan_fit_range(massfunc, tlist_corr,mass, par_mass)
            # TODO: set two points more than wanted for upper limit
            ranges = ana.set_fit_intervall(mass, [10], [24], 12)
            print len(ranges)
            res, chi2, pval = ana.genfit(mass,ranges,massfunc,
                par_mass,1,ens[:-1],np.asarray([0,0,0]),label,tmp_out,"mass")
            #ana.corr_fct_with_fit(tlist_corr[:-2], mmass, dmass, massfunc, res[0],
            #                     [1,T2], label, pfit, False, False)
            #print("m_k = %e +/- %e" %(np.median(res),np.std(res)))

            #pfit.close()
            print res[0,:,:,:]
            np.append(m_k_dat,res)
            print res.shape
            m_k_w, dm_stat, dm_sys =  ana.sys_error(res[:,0],pval,np.asarray([0,0,0]),ens[:-1])
            print m_k_w, dm_stat, dm_sys


            #-------------- Ratio of C_kk and C_k^2 ----------------------

            R_boot, R_mean, R_stdev, = ana.simple_ratio_subtract(bsamples_kk, bsamples_k, bsamples_k)
            # initial p (A, deltaE, E_k)
            label = ["Ratio K-K, "+ens, "time", "R(t)", "data", ""]
            # define the ratiofunction, Use fitted energies for better results
            ratio = lambda p, t, e : p[0]*(np.cosh(p[1]*(t-T/2))+np.sinh(p[1]*(t-T/2))/(np.tanh(2*e*(t-T/2))))
            #ratio = lambda p, t : p[0]*(np.cosh(p[1]*(t-T/2))+np.sinh(p[1]*(t-T/2))/(np.tanh(2*p[2]*(t-T/2))))
            # define fit ranges
            lobound = 12
            upbound = 22
            res_R, chi2_R, pvals_R = ana.genfit_comb(R_boot,ranges,ranges,ratio,par_ratio,res,
                1,ens[:-1],label,tmp_out,"ratio")
            # Reshape res_R and pvals_R for systematic error calculation
            r = 9 
            print res_R.size, pvals_R.size
            print r, nbsamples 
            w_res_R = np.reshape(res_R, (nbsamples,3,1,r))
            w_pvals_R = np.reshape(pvals_R, (nbsamples,1,1,r))
            #print w_res_R.shape, w_pvals_R.shape
            del_E_w, ddel_E_stat, ddel_E_sys = ana.sys_error(w_res_R[:,1],w_pvals_R,np.asarray([0,0,0]),ens[:-1])
            print del_E_w, ddel_E_stat, ddel_E_sys
            prat.close()

            a_k_dat[s] = ana.calc_scat_length(res_R[:,1],m_k_dat[s],L)
            m_k_akk = a_k_dat[s]*m_k_dat[s]
            print("amu_s\tm_k +/- d_stat(m_k)\t delE +/- d_stat(delE) \ta_kk +/- d_stat(a_kk)\tm_k*a_kk +/- d_stat(m_k*a_kk)") 
            print("%f\t%f +/- %f\t%f +/- %f\t%f +/- %f\t%f +/- %e"%(amu_s[s],
              np.median(m_k_dat[s]), np.std(m_k_dat[s]),np.median(delE_dat),
              np.std(delE_dat), np.median(a_k_dat[s]), np.std(a_k_dat[s]),
              np.median(m_k_akk), np.std(m_k_akk) ))


        ##----------------- Start analysis ------------------------------------------

        ## reshape data by switching axes
        #a_k_fin = a_k_dat.T
        #m_k_fin = m_k_dat.T

        ## Unitary mass matching of amu_s
        ## fit samples to straight line
        ##linear fitfunction
        #par_match = [0.1,2.]
        #m_k2 = lambda p, mu : p[0]*mu+p[1]
        #res_m2, chi2_m2, pvals_m2 = ana.fitting(m_k2,
        #    np.asarray(amu_s)[1:], m_k_fin[:,1:]**2, par_match, None, False, False)

        ## Create parametrized bootstrap samples for unitary mass
        #mk_u = np.random.normal(mk_unit, dmk_unit, len(corrs_k[0]))
        #m_k_unit = ana.bootstrap(mk_u, nbsamples)
        ## extract nb_samples amu_s values
        #amu_s_fin = (m_k_unit**2-res_m2[:,1])/res_m2[:,0] 
        ## print out mean and standard deviation
        ##print("amu_s from unitary Kaon matching:")
        ##print("amu_s^unit: %f +/- %f\n" % (np.median(amu_s_fin), np.std(amu_s_fin)))
        #
        ## Extract a_kk*am_k
        #par_match = [0.5,-2]
        #res_makk, chi2_makk, pvals_makk = ana.fitting(m_k2,
        #    np.asarray(amu_s)[1:], a_k_fin[:,1:]*m_k_fin[:,1:], par_match, None,
        #    False, False)
        #akk_mk = res_makk[:,1]+res_makk[:,0]*amu_s_fin
        ##print("Extracted m_k*a_kk:")
        ##print("m_k*akk: %f +/- %f\n" % (np.median(akk_mk), np.std(akk_mk)))
        ###plot data
        ##pscat = PdfPages("%s%skk_.pdf" % (tmp_out,"a_"))
        ###fit linear functions
        ##coef,stats = P.polyfit(scat_dat[:,0], scat_dat[:,1]**2,1,None,True,scat_dat[:,2]**2)
        ##print(coef, stats)
        ###linear fitfunction
        ##m_k2 = lambda p, mu : p[0]*mu+p[1]
        ###plot data with linear regression
        ##m_k_sq = ["Kaon scatt. length",  "a_mu_s", "m_K^2","A40.24", "data", ""]
        ##
        ##ana.corr_fct_with_fit(scat_dat[:,0],scat_dat[:,1]**2,scat_dat[:,2]**2,m_k2,
        ##    coef[::-1], [0,2],m_k_sq, pscat, False, False, [0.0185,0.02464])
        ##pscat.close()


# make this script importable, according to the Google Python Style Guide
if __name__ == '__main__':
    try:
        main()
    except KeyboardInterrupt:
        print("Keyboard Interrupt")
